{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4P6famYuqsZ",
        "outputId": "7c2e2686-deca-4faf-95ae-277d1a6193ed"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def separate_integers_letters(string):\n",
        "    integers = ''.join(re.findall(r'\\d+', string))\n",
        "    letters = ''.join(re.findall(r'[a-zA-Z]+', string))\n",
        "    return integers, letters"
      ],
      "metadata": {
        "id": "G7vNLKpquviM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dico_encodage = {'E_Bleu': 1, 'E_Rouge': 2, 'L_Bleu': 3, 'L_Rouge': 4}\n",
        "print(dico_encodage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBAMHR5tpsV_",
        "outputId": "1c80cd89-b760-4c15-84b9-b73d3d60ee79"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'E_Bleu': 1, 'E_Rouge': 2, 'L_Bleu': 3, 'L_Rouge': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def add_labels(df):\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    station_name_parts = row['station_name'].split('/')\n",
        "    position_dynamique = station_name_parts[2]\n",
        "    position_dynamique_parts = position_dynamique.split('_')\n",
        "    _, position = separate_integers_letters(position_dynamique_parts[1])\n",
        "    dynamique = position_dynamique_parts[2]\n",
        "\n",
        "    position_dynamique = position + '_' + dynamique\n",
        "\n",
        "    df.loc[index, 'label'] = dico_encodage[position_dynamique]\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "6u-imu7YuxkW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def custom_cross_validation(model, X_train, y_train, X_test, y_test):\n",
        "    # Entraîner le modèle sur l'ensemble de données d'entraînement\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prédire les étiquettes sur l'ensemble de test\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculer la précision du modèle\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "O6NM8m0lu0IM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s8RER9pRtyqv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0e38339-f6a8-4653-d492-6b8ce80b275c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier dossier_1 (train : 80.63% / test : 19.37%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.3\n",
            "Précision sur l'ensemble de test avec MLP : 0.32\n",
            "Précision sur l'ensemble de test avec GB : 0.3\n",
            "Moyenne des précisions : 0.31\n",
            "\n",
            "Dossier dossier_2 (train : 77.71% / test : 22.29%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.34\n",
            "Précision sur l'ensemble de test avec MLP : 0.36\n",
            "Précision sur l'ensemble de test avec GB : 0.33\n",
            "Moyenne des précisions : 0.34\n",
            "\n",
            "Dossier dossier_3 (train : 79.52% / test : 20.48%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.43\n",
            "Précision sur l'ensemble de test avec MLP : 0.36\n",
            "Précision sur l'ensemble de test avec GB : 0.38\n",
            "Moyenne des précisions : 0.39\n",
            "\n",
            "Dossier dossier_4 (train : 82.12% / test : 17.88%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.43\n",
            "Précision sur l'ensemble de test avec MLP : 0.35\n",
            "Précision sur l'ensemble de test avec GB : 0.42\n",
            "Moyenne des précisions : 0.4\n",
            "\n",
            "Dossier dossier_5 (train : 80.02% / test : 19.98%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.41\n",
            "Précision sur l'ensemble de test avec MLP : 0.37\n",
            "Précision sur l'ensemble de test avec GB : 0.4\n",
            "Moyenne des précisions : 0.39\n",
            "\n",
            "=======================================================================\n",
            "\n",
            "Moyenne des précisions avec RF : 0.38\n",
            "Moyenne des précisions avec MLP : 0.35\n",
            "Moyenne des précisions avec GB : 0.37\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Chemin vers le répertoire contenant les dossiers de données sur Google Drive\n",
        "data_directory = \"/content/gdrive/MyDrive/ListenToTheWild/vggish_day_temporal\"\n",
        "\n",
        "# Liste des dossiers dans le répertoire\n",
        "directories = sorted(os.listdir(data_directory))\n",
        "\n",
        "rf_mean_acc = 0\n",
        "mlp_mean_acc = 0\n",
        "gb_mean_acc = 0\n",
        "# Boucle sur chaque dossier\n",
        "for directory in directories:\n",
        "  # Chemin vers le dossier contenant les fichiers de train/test\n",
        "  directory_path = os.path.join(data_directory, directory)\n",
        "\n",
        "  # Charger les données d'entraînement\n",
        "  train_data = pd.read_csv(os.path.join(directory_path, \"vggish_day_temporal_train.csv\"))\n",
        "  nb_rows_train = train_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  train_data_with_labels = add_labels(train_data)\n",
        "  # Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "  train_data_with_labels = train_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_train = train_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_train = train_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Charger les données de test\n",
        "  test_data = pd.read_csv(os.path.join(directory_path, \"vggish_day_temporal_test.csv\"))\n",
        "  nb_rows_test = test_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  test_data_with_labels = add_labels(test_data)\n",
        "  # Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "  test_data_with_labels = test_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_test = test_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_test = test_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Créer les modèles\n",
        "  rf_model = RandomForestClassifier()\n",
        "  mlp_model = MLPClassifier()\n",
        "  gb_model = GradientBoostingClassifier()\n",
        "\n",
        "  # Effectuer les validations croisées personnalisées\n",
        "  rf_accuracy = custom_cross_validation(rf_model, X_train, y_train, X_test, y_test)\n",
        "  mlp_accuracy = custom_cross_validation(mlp_model, X_train, y_train, X_test, y_test)\n",
        "  gb_accuracy = custom_cross_validation(gb_model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "  # Calculer la moyenne des précisions\n",
        "  mean_accuracy = (rf_accuracy + mlp_accuracy + gb_accuracy)/3\n",
        "\n",
        "  # Ajouter les valeurs pour le calcul des moyennes\n",
        "  rf_mean_acc += rf_accuracy\n",
        "  mlp_mean_acc += mlp_accuracy\n",
        "  gb_mean_acc += gb_accuracy\n",
        "\n",
        "  # Calculer les pourcentages des ensembles\n",
        "  per_train_set = nb_rows_train / (nb_rows_train + nb_rows_test)\n",
        "  per_test_set = nb_rows_test / (nb_rows_train + nb_rows_test)\n",
        "\n",
        "  # Afficher les précisions sur l'ensemble de test\n",
        "  print(f\"Dossier {directory} (train : {round(per_train_set*100, 2)}% / test : {round(per_test_set*100, 2)}%) :\")\n",
        "  print(f\"Précision sur l'ensemble de test avec RF : {round(rf_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec MLP : {round(mlp_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec GB : {round(gb_accuracy, 2)}\")\n",
        "  print(f\"Moyenne des précisions : {round(mean_accuracy, 2)}\")\n",
        "  print()\n",
        "\n",
        "print(\"=======================================================================\")\n",
        "print()\n",
        "\n",
        "# Afficher les moyennes des précisions par modèle\n",
        "nb_dir = len(directories)\n",
        "print(f\"Moyenne des précisions avec RF : {round(rf_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec MLP : {round(mlp_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec GB : {round(gb_mean_acc/nb_dir, 2)}\")"
      ]
    }
  ]
}