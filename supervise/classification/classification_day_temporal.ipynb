{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4P6famYuqsZ",
        "outputId": "90089ee3-9c3d-4e8c-c776-d605718de25f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def separate_integers_letters(string):\n",
        "    integers = ''.join(re.findall(r'\\d+', string))\n",
        "    letters = ''.join(re.findall(r'[a-zA-Z]+', string))\n",
        "    return integers, letters"
      ],
      "metadata": {
        "id": "G7vNLKpquviM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def add_labels(df):\n",
        "  label_encoder = LabelEncoder()\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    station_name_parts = row['station_name'].split('/')\n",
        "    position_dynamique = station_name_parts[2]\n",
        "    position_dynamique_parts = position_dynamique.split('_')\n",
        "    _, position = separate_integers_letters(position_dynamique_parts[1])\n",
        "    dynamique = position_dynamique_parts[2]\n",
        "\n",
        "    df.loc[index, 'position'] = position\n",
        "    df.loc[index, 'dynamique'] = dynamique\n",
        "\n",
        "  df['position'] = label_encoder.fit_transform(df['position'])\n",
        "  df['dynamique'] = label_encoder.fit_transform(df['dynamique'])\n",
        "\n",
        "  df['label'] = df['position'].astype(str) + df['dynamique'].astype(str)\n",
        "  df = df.drop(['position', 'dynamique'], axis=1)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "6u-imu7YuxkW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def custom_cross_validation(model, X_train, y_train, X_test, y_test):\n",
        "    # Entraîner le modèle sur l'ensemble de données d'entraînement\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prédire les étiquettes sur l'ensemble de test\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculer la précision du modèle\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "O6NM8m0lu0IM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s8RER9pRtyqv",
        "outputId": "9c495755-964d-405b-f1a3-ff190e98423f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier day_temporal (train : 80.02% / test : 19.98%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.37\n",
            "Précision sur l'ensemble de test avec MLP : 0.23\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.31\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Chemin vers le répertoire contenant les dossiers de données sur Google Drive\n",
        "data_directory = \"/content/gdrive/MyDrive/ListenToTheWild/day_temporal\"\n",
        "\n",
        "directory = \"day_temporal\"\n",
        "\n",
        "# Charger les données d'entraînement\n",
        "train_data = pd.read_csv(os.path.join(data_directory, f\"{directory}_train.csv\"))\n",
        "nb_rows_train = train_data.shape[0]\n",
        "# Ajouter les labels\n",
        "train_data_with_labels = add_labels(train_data)\n",
        "# Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "train_data_with_labels = train_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "# Pour supprimer les NaN\n",
        "train_data_with_labels = train_data_with_labels.drop(['Ht', 'ACTtMean', 'TFSD'], axis=1)\n",
        "# Créer X et y\n",
        "X_train = train_data_with_labels.drop(columns=['label'])  # attributs\n",
        "y_train = train_data_with_labels['label']  # étiquettes\n",
        "\n",
        "# Charger les données de test\n",
        "test_data = pd.read_csv(os.path.join(data_directory, f\"{directory}_test.csv\"))\n",
        "nb_rows_test = test_data.shape[0]\n",
        "# Ajouter les labels\n",
        "test_data_with_labels = add_labels(test_data)\n",
        "# Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "test_data_with_labels = test_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "# Pour supprimer les NaN\n",
        "test_data_with_labels = test_data_with_labels.drop(['Ht', 'ACTtMean', 'TFSD'], axis=1)\n",
        "# Créer X et y\n",
        "X_test = test_data_with_labels.drop(columns=['label'])  # attributs\n",
        "y_test = test_data_with_labels['label']  # étiquettes\n",
        "\n",
        "# Créer les modèles\n",
        "rf_model = RandomForestClassifier()\n",
        "mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500)\n",
        "gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
        "\n",
        "# Effectuer les validations croisées personnalisées\n",
        "rf_accuracy = custom_cross_validation(rf_model, X_train, y_train, X_test, y_test)\n",
        "mlp_accuracy = custom_cross_validation(mlp_model, X_train, y_train, X_test, y_test)\n",
        "gb_accuracy = custom_cross_validation(gb_model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "# Calculer la moyenne des précisions\n",
        "mean_accuracy = (rf_accuracy + mlp_accuracy + gb_accuracy)/3\n",
        "\n",
        "# Calculer les pourcentages des ensembles\n",
        "per_train_set = nb_rows_train / (nb_rows_train + nb_rows_test)\n",
        "per_test_set = nb_rows_test / (nb_rows_train + nb_rows_test)\n",
        "\n",
        "# Afficher les précisions sur l'ensemble de test\n",
        "print(f\"Dossier {directory} (train : {round(per_train_set*100, 2)}% / test : {round(per_test_set*100, 2)}%) :\")\n",
        "print(f\"Précision sur l'ensemble de test avec RF : {round(rf_accuracy, 2)}\")\n",
        "print(f\"Précision sur l'ensemble de test avec MLP : {round(mlp_accuracy, 2)}\")\n",
        "print(f\"Précision sur l'ensemble de test avec GB : {round(gb_accuracy, 2)}\")\n",
        "print(f\"Moyenne des précisions : {round(mean_accuracy, 2)}\")\n",
        "print()"
      ]
    }
  ]
}