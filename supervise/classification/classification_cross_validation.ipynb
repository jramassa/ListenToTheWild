{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTYZLuAEfqIg"
      },
      "source": [
        "# Classification cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bnGDveyfqIi"
      },
      "source": [
        "## 1. Ségrégation spatiale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQLXY-I9fqIi"
      },
      "source": [
        "### a) Création des .csv pour les ensembles de test et de train (NE PAS LANCER SUR COLAB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrtbKmnDfqIj",
        "outputId": "4feee2ca-0bc5-40eb-9a00-ad56c6dbeddb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:2: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Antras_Isard', 'Appy_Etang_dAppy', 'Arrien_Pic_Midi_Bordes', 'Ascou_Pailheres', 'Aston_Plateau_de_Beille', 'Aulus_Turon_Rose', 'Bestiac_Trimouns', 'Bethmale_Ayet', 'Bethmale_Eychelle', 'Bonac_Arech', 'Bonac_Orle', 'Couflens_Pouill', 'Couflens_SaubÃ©', 'FormiguÃ¨res_Serra_dels_Alarbs', 'GestiÃ¨s_Col_du_Sasc', 'GestiÃ¨s_Le_Clot', 'Goulier_Val_de_Sos', 'Lercoul_Col_de_Grail', 'Les_Angles_Puig_del_Pam', 'Les_Angles_Roc_dAude', 'Merens_Comte', 'Miglos_Pla_de_Montcamp', 'Mijanes_Estagnet', 'Mijanes_Trabesses', 'Montferrier_Mont_dOlmes', 'Montsegur_Frau', 'MontsÃ©gur_Soularac', 'Orgeix_Coume', 'Orlu_RNCFS', 'Saint-Lary_Herbe_Soulette', 'Seix_Col_de_Pause', 'Seix_Pic_de_Montbuou', 'Sentein_Eylie', 'Ustou_Col_dEscots', 'Ustou_Guzet-Neige', 'ValcebollÃ¨re_Pla_des_Salines']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "df_csv = pd.read_csv('../Valeurs_acoustiques/concatenated_acoustic_indices.csv')\n",
        "df_test_sets = []\n",
        "df_train_sets = []\n",
        "\n",
        "# Créer l'ensemble des stations\n",
        "with open('../Valeurs_acoustiques/concatenated_acoustic_indices.csv', mode='r', encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.DictReader(csv_file)\n",
        "\n",
        "    list_stations = []\n",
        "    for row in csv_reader:\n",
        "        station_name_parts = row['station_name'].split('/')\n",
        "        station_name = station_name_parts[1]\n",
        "        list_stations.append(station_name)\n",
        "\n",
        "    set_stations = sorted(set(list_stations)) # sorted pour ordre alphabétique\n",
        "\n",
        "print(set_stations)\n",
        "\n",
        "# Créer les dataframes pour test et train pour la ségrégation spatiale\n",
        "for station in set_stations:\n",
        "    df_test = pd.DataFrame(columns=['file_name', 'station_name',\t'ZCR', 'MEANt', 'VARt',\t'SKEWt', 'KURTt', 'LEQt', 'BGNt', 'SNRt', 'MED', 'Ht', 'ACTtFraction', 'ACTtCount', 'ACTtMean', 'EVNtFraction', 'EVNtMean', 'EVNtCount', 'MEANf', 'VARf', 'SKEWf', 'KURTf', 'NBPEAKS', 'LEQf', 'ENRf', 'BGNf', 'SNRf', 'Hf', 'EAS', 'ECU', 'ECV', 'EPS', 'EPS_KURT', 'EPS_SKEW', 'ACI', 'NDSI', 'rBA', 'AnthroEnergy', 'BioEnergy', 'BI', 'ROU', 'ADI', 'AEI', 'LFC', 'MFC', 'HFC', 'ACTspFract', 'ACTspCount', 'ACTspMean', 'EVNspFract', 'EVNspMean', 'EVNspCount', 'TFSD', 'H_Havrda', 'H_Renyi', 'H_pairedShannon', 'H_gamma', 'H_GiniSimpson', 'RAOQ', 'AGI', 'ROItotal', 'ROIcover'])\n",
        "    df_train = pd.DataFrame(columns=['file_name', 'station_name',\t'ZCR', 'MEANt', 'VARt',\t'SKEWt', 'KURTt', 'LEQt', 'BGNt', 'SNRt', 'MED', 'Ht', 'ACTtFraction', 'ACTtCount', 'ACTtMean', 'EVNtFraction', 'EVNtMean', 'EVNtCount', 'MEANf', 'VARf', 'SKEWf', 'KURTf', 'NBPEAKS', 'LEQf', 'ENRf', 'BGNf', 'SNRf', 'Hf', 'EAS', 'ECU', 'ECV', 'EPS', 'EPS_KURT', 'EPS_SKEW', 'ACI', 'NDSI', 'rBA', 'AnthroEnergy', 'BioEnergy', 'BI', 'ROU', 'ADI', 'AEI', 'LFC', 'MFC', 'HFC', 'ACTspFract', 'ACTspCount', 'ACTspMean', 'EVNspFract', 'EVNspMean', 'EVNspCount', 'TFSD', 'H_Havrda', 'H_Renyi', 'H_pairedShannon', 'H_gamma', 'H_GiniSimpson', 'RAOQ', 'AGI', 'ROItotal', 'ROIcover'])\n",
        "    for index, row in df_csv.iterrows():\n",
        "        station_name_parts = row['station_name'].split('/')\n",
        "        station_name = station_name_parts[1]\n",
        "\n",
        "        if station_name == station:\n",
        "            df_test = df_test._append(row, ignore_index=True)\n",
        "        else:\n",
        "            df_train = df_train._append(row, ignore_index=True)\n",
        "\n",
        "    df_test_sets += [df_test]\n",
        "    df_train_sets += [df_train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96rdVnVmfqIk",
        "outputId": "9a94275b-0202-4e67-ff5d-4b6032a0049f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30549\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "print(len(df_test_sets[1]) + len(df_train_sets[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elVTAR-kfqIl"
      },
      "outputs": [],
      "source": [
        "# Créer les .csv\n",
        "\n",
        "import os\n",
        "\n",
        "# Déplacer vers un dossier spécifique\n",
        "nouveau_dossier = \"../output_csv/cross_validation_spatial\"\n",
        "os.chdir(nouveau_dossier)\n",
        "\n",
        "for i in range(len(set_stations)):\n",
        "    os.makedirs(set_stations[i], exist_ok=True)\n",
        "\n",
        "    path_test = set_stations[i]+\"/\" + set_stations[i] + \"_test.csv\"\n",
        "    path_train = set_stations[i]+\"/\" + set_stations[i] + \"_train.csv\"\n",
        "\n",
        "    df_test_sets[i].to_csv(path_test, index=False)\n",
        "    df_train_sets[i].to_csv(path_train, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57mmZlxufqIl"
      },
      "source": [
        "### b) Tests sur différents modèles (A LANCER SUR COLAB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRfJ7QB6fw2Q",
        "outputId": "f2a9096c-568e-4615-a5f8-0ee2aadd4ec1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c8KaHzptxq36"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def separate_integers_letters(string):\n",
        "    integers = ''.join(re.findall(r'\\d+', string))\n",
        "    letters = ''.join(re.findall(r'[a-zA-Z]+', string))\n",
        "    return integers, letters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V8O_afOTo0aB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def add_labels(df):\n",
        "  label_encoder = LabelEncoder()\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    station_name_parts = row['station_name'].split('/')\n",
        "    position_dynamique = station_name_parts[2]\n",
        "    position_dynamique_parts = position_dynamique.split('_')\n",
        "    _, position = separate_integers_letters(position_dynamique_parts[1])\n",
        "    dynamique = position_dynamique_parts[2]\n",
        "\n",
        "    df.loc[index, 'position'] = position\n",
        "    df.loc[index, 'dynamique'] = dynamique\n",
        "\n",
        "  df['position'] = label_encoder.fit_transform(df['position'])\n",
        "  df['dynamique'] = label_encoder.fit_transform(df['dynamique'])\n",
        "\n",
        "  df['label'] = df['position'].astype(str) + df['dynamique'].astype(str)\n",
        "  df = df.drop(['position', 'dynamique'], axis=1)\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "GlEJoORrhXhE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def custom_cross_validation(model, X_train, y_train, X_test, y_test):\n",
        "    # Entraîner le modèle sur l'ensemble de données d'entraînement\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prédire les étiquettes sur l'ensemble de test\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculer la précision du modèle\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glOVwpTxfqIl",
        "outputId": "f142daa3-abc0-49ef-973e-8400603868b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dossier Antras_Isard (train : 95.46% / test : 4.54%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.29\n",
            "Précision sur l'ensemble de test avec MLP : 0.41\n",
            "Précision sur l'ensemble de test avec GB : 0.31\n",
            "Moyenne des précisions : 0.34\n",
            "\n",
            "Dossier Appy_Etang_dAppy (train : 97.81% / test : 2.19%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.3\n",
            "Précision sur l'ensemble de test avec MLP : 0.33\n",
            "Précision sur l'ensemble de test avec GB : 0.21\n",
            "Moyenne des précisions : 0.28\n",
            "\n",
            "Dossier Arrien_Pic_Midi_Bordes (train : 95.68% / test : 4.32%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.35\n",
            "Précision sur l'ensemble de test avec GB : 0.36\n",
            "Moyenne des précisions : 0.36\n",
            "\n",
            "Dossier Ascou_Pailheres (train : 98.02% / test : 1.98%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.44\n",
            "Précision sur l'ensemble de test avec GB : 0.33\n",
            "Moyenne des précisions : 0.37\n",
            "\n",
            "Dossier Aston_Plateau_de_Beille (train : 98.14% / test : 1.86%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.38\n",
            "Précision sur l'ensemble de test avec MLP : 0.36\n",
            "Précision sur l'ensemble de test avec GB : 0.38\n",
            "Moyenne des précisions : 0.37\n",
            "\n",
            "Dossier Aulus_Turon_Rose (train : 97.8% / test : 2.2%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.44\n",
            "Précision sur l'ensemble de test avec MLP : 0.33\n",
            "Précision sur l'ensemble de test avec GB : 0.44\n",
            "Moyenne des précisions : 0.4\n",
            "\n",
            "Dossier Bestiac_Trimouns (train : 97.24% / test : 2.76%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.25\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.31\n",
            "\n",
            "Dossier Bethmale_Ayet (train : 99.06% / test : 0.94%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.44\n",
            "Précision sur l'ensemble de test avec MLP : 0.29\n",
            "Précision sur l'ensemble de test avec GB : 0.37\n",
            "Moyenne des précisions : 0.37\n",
            "\n",
            "Dossier Bethmale_Eychelle (train : 98.1% / test : 1.9%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.28\n",
            "Précision sur l'ensemble de test avec MLP : 0.34\n",
            "Précision sur l'ensemble de test avec GB : 0.39\n",
            "Moyenne des précisions : 0.34\n",
            "\n",
            "Dossier Bonac_Arech (train : 97.48% / test : 2.52%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.39\n",
            "Précision sur l'ensemble de test avec MLP : 0.26\n",
            "Précision sur l'ensemble de test avec GB : 0.38\n",
            "Moyenne des précisions : 0.34\n",
            "\n",
            "Dossier Bonac_Orle (train : 95.61% / test : 4.39%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.18\n",
            "Précision sur l'ensemble de test avec MLP : 0.24\n",
            "Précision sur l'ensemble de test avec GB : 0.22\n",
            "Moyenne des précisions : 0.22\n",
            "\n",
            "Dossier Couflens_Pouill (train : 99.08% / test : 0.92%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.31\n",
            "Précision sur l'ensemble de test avec MLP : 0.29\n",
            "Précision sur l'ensemble de test avec GB : 0.27\n",
            "Moyenne des précisions : 0.29\n",
            "\n",
            "Dossier Couflens_Saubé (train : 99.34% / test : 0.66%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.34\n",
            "Précision sur l'ensemble de test avec MLP : 0.04\n",
            "Précision sur l'ensemble de test avec GB : 0.25\n",
            "Moyenne des précisions : 0.21\n",
            "\n",
            "Dossier Formiguères_Serra_dels_Alarbs (train : 95.7% / test : 4.3%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.24\n",
            "Précision sur l'ensemble de test avec MLP : 0.24\n",
            "Précision sur l'ensemble de test avec GB : 0.26\n",
            "Moyenne des précisions : 0.25\n",
            "\n",
            "Dossier Gestiès_Col_du_Sasc (train : 98.58% / test : 1.42%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.26\n",
            "Précision sur l'ensemble de test avec MLP : 0.2\n",
            "Précision sur l'ensemble de test avec GB : 0.27\n",
            "Moyenne des précisions : 0.24\n",
            "\n",
            "Dossier Gestiès_Le_Clot (train : 97.82% / test : 2.18%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.39\n",
            "Précision sur l'ensemble de test avec MLP : 0.39\n",
            "Précision sur l'ensemble de test avec GB : 0.41\n",
            "Moyenne des précisions : 0.39\n",
            "\n",
            "Dossier Goulier_Val_de_Sos (train : 98.19% / test : 1.81%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.38\n",
            "Précision sur l'ensemble de test avec MLP : 0.25\n",
            "Précision sur l'ensemble de test avec GB : 0.25\n",
            "Moyenne des précisions : 0.29\n",
            "\n",
            "Dossier Lercoul_Col_de_Grail (train : 98.14% / test : 1.86%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.39\n",
            "Précision sur l'ensemble de test avec MLP : 0.4\n",
            "Précision sur l'ensemble de test avec GB : 0.41\n",
            "Moyenne des précisions : 0.4\n",
            "\n",
            "Dossier Les_Angles_Puig_del_Pam (train : 95.33% / test : 4.67%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.22\n",
            "Précision sur l'ensemble de test avec MLP : 0.17\n",
            "Précision sur l'ensemble de test avec GB : 0.2\n",
            "Moyenne des précisions : 0.2\n",
            "\n",
            "Dossier Les_Angles_Roc_dAude (train : 95.42% / test : 4.58%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.27\n",
            "Précision sur l'ensemble de test avec MLP : 0.29\n",
            "Précision sur l'ensemble de test avec GB : 0.2\n",
            "Moyenne des précisions : 0.25\n",
            "\n",
            "Dossier Merens_Comte (train : 95.99% / test : 4.01%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.13\n",
            "Précision sur l'ensemble de test avec MLP : 0.2\n",
            "Précision sur l'ensemble de test avec GB : 0.12\n",
            "Moyenne des précisions : 0.15\n",
            "\n",
            "Dossier Miglos_Pla_de_Montcamp (train : 98.14% / test : 1.86%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.32\n",
            "Précision sur l'ensemble de test avec MLP : 0.27\n",
            "Précision sur l'ensemble de test avec GB : 0.35\n",
            "Moyenne des précisions : 0.31\n",
            "\n",
            "Dossier Mijanes_Estagnet (train : 96.3% / test : 3.7%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.35\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.35\n",
            "\n",
            "Dossier Mijanes_Trabesses (train : 97.3% / test : 2.7%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.28\n",
            "Précision sur l'ensemble de test avec MLP : 0.33\n",
            "Précision sur l'ensemble de test avec GB : 0.2\n",
            "Moyenne des précisions : 0.27\n",
            "\n",
            "Dossier Montferrier_Mont_dOlmes (train : 97.46% / test : 2.54%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.3\n",
            "Précision sur l'ensemble de test avec MLP : 0.33\n",
            "Précision sur l'ensemble de test avec GB : 0.31\n",
            "Moyenne des précisions : 0.31\n",
            "\n",
            "Dossier Montsegur_Frau (train : 98.88% / test : 1.12%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.19\n",
            "Précision sur l'ensemble de test avec MLP : 0.12\n",
            "Précision sur l'ensemble de test avec GB : 0.17\n",
            "Moyenne des précisions : 0.16\n",
            "\n",
            "Dossier Montségur_Soularac (train : 94.78% / test : 5.22%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.36\n",
            "Précision sur l'ensemble de test avec MLP : 0.36\n",
            "Précision sur l'ensemble de test avec GB : 0.47\n",
            "Moyenne des précisions : 0.4\n",
            "\n",
            "Dossier Orgeix_Coume (train : 97.55% / test : 2.45%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.46\n",
            "Précision sur l'ensemble de test avec MLP : 0.19\n",
            "Précision sur l'ensemble de test avec GB : 0.37\n",
            "Moyenne des précisions : 0.34\n",
            "\n",
            "Dossier Orlu_RNCFS (train : 96.31% / test : 3.69%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.24\n",
            "Précision sur l'ensemble de test avec MLP : 0.16\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.25\n",
            "\n",
            "Dossier Saint-Lary_Herbe_Soulette (train : 98.02% / test : 1.98%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.42\n",
            "Précision sur l'ensemble de test avec MLP : 0.35\n",
            "Précision sur l'ensemble de test avec GB : 0.41\n",
            "Moyenne des précisions : 0.39\n",
            "\n",
            "Dossier Seix_Col_de_Pause (train : 98.23% / test : 1.77%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.37\n",
            "Précision sur l'ensemble de test avec GB : 0.4\n",
            "Moyenne des précisions : 0.38\n",
            "\n",
            "Dossier Seix_Pic_de_Montbuou (train : 95.73% / test : 4.27%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.3\n",
            "Précision sur l'ensemble de test avec MLP : 0.3\n",
            "Précision sur l'ensemble de test avec GB : 0.29\n",
            "Moyenne des précisions : 0.3\n",
            "\n",
            "Dossier Sentein_Eylie (train : 95.89% / test : 4.11%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.3\n",
            "Précision sur l'ensemble de test avec GB : 0.44\n",
            "Moyenne des précisions : 0.36\n",
            "\n",
            "Dossier Ustou_Col_dEscots (train : 95.93% / test : 4.07%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.15\n",
            "Précision sur l'ensemble de test avec MLP : 0.26\n",
            "Précision sur l'ensemble de test avec GB : 0.14\n",
            "Moyenne des précisions : 0.19\n",
            "\n",
            "Dossier Ustou_Guzet-Neige (train : 98.76% / test : 1.24%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.5\n",
            "Précision sur l'ensemble de test avec GB : 0.26\n",
            "Moyenne des précisions : 0.37\n",
            "\n",
            "Dossier Valcebollère_Pla_des_Salines (train : 96.73% / test : 3.27%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.12\n",
            "Précision sur l'ensemble de test avec MLP : 0.16\n",
            "Précision sur l'ensemble de test avec GB : 0.16\n",
            "Moyenne des précisions : 0.15\n",
            "\n",
            "=======================================================================\n",
            "\n",
            "Moyenne des précisions avec RF : 0.31\n",
            "Moyenne des précisions avec MLP : 0.29\n",
            "Moyenne des précisions avec GB : 0.31\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Chemin vers le répertoire contenant les dossiers de données sur Google Drive\n",
        "data_directory = \"/content/gdrive/MyDrive/ListenToTheWild/cross_validation_spatial\"\n",
        "\n",
        "# Liste des dossiers dans le répertoire\n",
        "directories = sorted(os.listdir(data_directory))\n",
        "\n",
        "rf_mean_acc = 0\n",
        "mlp_mean_acc = 0\n",
        "gb_mean_acc = 0\n",
        "# Boucle sur chaque dossier\n",
        "for directory in directories:\n",
        "  # Chemin vers le dossier contenant les fichiers de train/test\n",
        "  directory_path = os.path.join(data_directory, directory)\n",
        "\n",
        "  # Charger les données d'entraînement\n",
        "  train_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_train.csv\"))\n",
        "  nb_rows_train = train_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  train_data_with_labels = add_labels(train_data)\n",
        "  # Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "  train_data_with_labels = train_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "  # Pour supprimer les NaN\n",
        "  train_data_with_labels = train_data_with_labels.drop(['Ht', 'ACTtMean', 'TFSD'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_train = train_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_train = train_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Charger les données de test\n",
        "  test_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_test.csv\"))\n",
        "  nb_rows_test = test_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  test_data_with_labels = add_labels(test_data)\n",
        "  # Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "  test_data_with_labels = test_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "  # Pour supprimer les NaN\n",
        "  test_data_with_labels = test_data_with_labels.drop(['Ht', 'ACTtMean', 'TFSD'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_test = test_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_test = test_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Créer les modèles\n",
        "  rf_model = RandomForestClassifier()\n",
        "  mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500)\n",
        "  gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
        "\n",
        "  # Effectuer les validations croisées personnalisées\n",
        "  rf_accuracy = custom_cross_validation(rf_model, X_train, y_train, X_test, y_test)\n",
        "  mlp_accuracy = custom_cross_validation(mlp_model, X_train, y_train, X_test, y_test)\n",
        "  gb_accuracy = custom_cross_validation(gb_model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "  # Calculer la moyenne des précisions\n",
        "  mean_accuracy = (rf_accuracy + mlp_accuracy + gb_accuracy)/3\n",
        "\n",
        "  # Ajouter les valeurs pour le calcul des moyennes\n",
        "  rf_mean_acc += rf_accuracy\n",
        "  mlp_mean_acc += mlp_accuracy\n",
        "  gb_mean_acc += gb_accuracy\n",
        "\n",
        "  # Calculer les pourcentages des ensembles\n",
        "  per_train_set = nb_rows_train / (nb_rows_train + nb_rows_test)\n",
        "  per_test_set = nb_rows_test / (nb_rows_train + nb_rows_test)\n",
        "\n",
        "  # Afficher les précisions sur l'ensemble de test\n",
        "  print(f\"Dossier {directory} (train : {round(per_train_set*100, 2)}% / test : {round(per_test_set*100, 2)}%) :\")\n",
        "  print(f\"Précision sur l'ensemble de test avec RF : {round(rf_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec MLP : {round(mlp_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec GB : {round(gb_accuracy, 2)}\")\n",
        "  print(f\"Moyenne des précisions : {round(mean_accuracy, 2)}\")\n",
        "  print()\n",
        "\n",
        "print(\"=======================================================================\")\n",
        "print()\n",
        "\n",
        "# Afficher les moyennes des précisions par modèle\n",
        "nb_dir = len(directories)\n",
        "print(f\"Moyenne des précisions avec RF : {round(rf_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec MLP : {round(mlp_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec GB : {round(gb_mean_acc/nb_dir, 2)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "ew_A0XXMpfyX",
        "outputId": "1fb905af-6211-49cd-80d2-17f1f152c942"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-23633480-9eb6-4d95-95c5-e155a2b64ffd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ZCR</th>\n",
              "      <th>MEANt</th>\n",
              "      <th>VARt</th>\n",
              "      <th>SKEWt</th>\n",
              "      <th>KURTt</th>\n",
              "      <th>LEQt</th>\n",
              "      <th>BGNt</th>\n",
              "      <th>SNRt</th>\n",
              "      <th>MED</th>\n",
              "      <th>ACTtFraction</th>\n",
              "      <th>...</th>\n",
              "      <th>H_Havrda</th>\n",
              "      <th>H_Renyi</th>\n",
              "      <th>H_pairedShannon</th>\n",
              "      <th>H_gamma</th>\n",
              "      <th>H_GiniSimpson</th>\n",
              "      <th>RAOQ</th>\n",
              "      <th>AGI</th>\n",
              "      <th>ROItotal</th>\n",
              "      <th>ROIcover</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1764.416667</td>\n",
              "      <td>0.000781</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.131073</td>\n",
              "      <td>4.761340</td>\n",
              "      <td>36.457276</td>\n",
              "      <td>-47.705630</td>\n",
              "      <td>0.623479</td>\n",
              "      <td>0.004118</td>\n",
              "      <td>0.071467</td>\n",
              "      <td>...</td>\n",
              "      <td>0.332788</td>\n",
              "      <td>3.207581</td>\n",
              "      <td>5.321909</td>\n",
              "      <td>23125.967137</td>\n",
              "      <td>0.970291</td>\n",
              "      <td>0.252875</td>\n",
              "      <td>1.213142</td>\n",
              "      <td>58</td>\n",
              "      <td>1.350616</td>\n",
              "      <td>00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1816.266667</td>\n",
              "      <td>-0.000061</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.154423</td>\n",
              "      <td>5.075730</td>\n",
              "      <td>38.797116</td>\n",
              "      <td>-46.109787</td>\n",
              "      <td>1.002794</td>\n",
              "      <td>0.004949</td>\n",
              "      <td>0.126400</td>\n",
              "      <td>...</td>\n",
              "      <td>0.331752</td>\n",
              "      <td>2.675398</td>\n",
              "      <td>4.682315</td>\n",
              "      <td>13875.470578</td>\n",
              "      <td>0.946628</td>\n",
              "      <td>0.134986</td>\n",
              "      <td>1.235006</td>\n",
              "      <td>135</td>\n",
              "      <td>2.326345</td>\n",
              "      <td>00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2054.350000</td>\n",
              "      <td>0.000394</td>\n",
              "      <td>0.000002</td>\n",
              "      <td>0.096852</td>\n",
              "      <td>8.235647</td>\n",
              "      <td>37.209411</td>\n",
              "      <td>-47.877052</td>\n",
              "      <td>1.495073</td>\n",
              "      <td>0.004038</td>\n",
              "      <td>0.149867</td>\n",
              "      <td>...</td>\n",
              "      <td>0.332604</td>\n",
              "      <td>3.062414</td>\n",
              "      <td>5.068941</td>\n",
              "      <td>17938.211022</td>\n",
              "      <td>0.964771</td>\n",
              "      <td>0.181781</td>\n",
              "      <td>1.225285</td>\n",
              "      <td>56</td>\n",
              "      <td>2.235776</td>\n",
              "      <td>00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1430.466667</td>\n",
              "      <td>0.000247</td>\n",
              "      <td>0.000016</td>\n",
              "      <td>0.295968</td>\n",
              "      <td>19.141701</td>\n",
              "      <td>44.954948</td>\n",
              "      <td>-44.820732</td>\n",
              "      <td>4.823176</td>\n",
              "      <td>0.005741</td>\n",
              "      <td>0.324267</td>\n",
              "      <td>...</td>\n",
              "      <td>0.327815</td>\n",
              "      <td>2.050577</td>\n",
              "      <td>3.741928</td>\n",
              "      <td>4689.881419</td>\n",
              "      <td>0.891058</td>\n",
              "      <td>0.032337</td>\n",
              "      <td>1.251943</td>\n",
              "      <td>52</td>\n",
              "      <td>5.205276</td>\n",
              "      <td>00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1308.400000</td>\n",
              "      <td>-0.001215</td>\n",
              "      <td>0.000003</td>\n",
              "      <td>0.060765</td>\n",
              "      <td>6.980352</td>\n",
              "      <td>39.593809</td>\n",
              "      <td>-46.251354</td>\n",
              "      <td>1.310539</td>\n",
              "      <td>0.004869</td>\n",
              "      <td>0.166400</td>\n",
              "      <td>...</td>\n",
              "      <td>0.331297</td>\n",
              "      <td>2.548900</td>\n",
              "      <td>4.722316</td>\n",
              "      <td>14745.415390</td>\n",
              "      <td>0.941337</td>\n",
              "      <td>0.147151</td>\n",
              "      <td>1.231857</td>\n",
              "      <td>85</td>\n",
              "      <td>2.485284</td>\n",
              "      <td>00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29157</th>\n",
              "      <td>2664.816667</td>\n",
              "      <td>0.000966</td>\n",
              "      <td>0.000005</td>\n",
              "      <td>0.061751</td>\n",
              "      <td>15.494871</td>\n",
              "      <td>40.420251</td>\n",
              "      <td>-44.081135</td>\n",
              "      <td>1.151237</td>\n",
              "      <td>0.006251</td>\n",
              "      <td>0.085867</td>\n",
              "      <td>...</td>\n",
              "      <td>0.333277</td>\n",
              "      <td>4.343159</td>\n",
              "      <td>6.263979</td>\n",
              "      <td>42059.466244</td>\n",
              "      <td>0.990679</td>\n",
              "      <td>0.744602</td>\n",
              "      <td>1.574344</td>\n",
              "      <td>367</td>\n",
              "      <td>6.982161</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29158</th>\n",
              "      <td>1991.066667</td>\n",
              "      <td>0.001092</td>\n",
              "      <td>0.000004</td>\n",
              "      <td>0.043957</td>\n",
              "      <td>3.429047</td>\n",
              "      <td>40.551362</td>\n",
              "      <td>-43.806730</td>\n",
              "      <td>0.529841</td>\n",
              "      <td>0.006452</td>\n",
              "      <td>0.046400</td>\n",
              "      <td>...</td>\n",
              "      <td>0.332787</td>\n",
              "      <td>3.206599</td>\n",
              "      <td>5.445871</td>\n",
              "      <td>25623.385626</td>\n",
              "      <td>0.971321</td>\n",
              "      <td>0.335342</td>\n",
              "      <td>1.310117</td>\n",
              "      <td>178</td>\n",
              "      <td>3.861851</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29159</th>\n",
              "      <td>4111.283333</td>\n",
              "      <td>0.000574</td>\n",
              "      <td>0.000011</td>\n",
              "      <td>0.211090</td>\n",
              "      <td>14.242911</td>\n",
              "      <td>43.652024</td>\n",
              "      <td>-43.533936</td>\n",
              "      <td>3.114562</td>\n",
              "      <td>0.006657</td>\n",
              "      <td>0.232000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.332504</td>\n",
              "      <td>2.998246</td>\n",
              "      <td>5.563157</td>\n",
              "      <td>33670.527993</td>\n",
              "      <td>0.966200</td>\n",
              "      <td>0.835676</td>\n",
              "      <td>2.200941</td>\n",
              "      <td>254</td>\n",
              "      <td>16.800731</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29160</th>\n",
              "      <td>1752.250000</td>\n",
              "      <td>0.000544</td>\n",
              "      <td>0.000069</td>\n",
              "      <td>-0.030005</td>\n",
              "      <td>7.864743</td>\n",
              "      <td>51.411486</td>\n",
              "      <td>-35.396584</td>\n",
              "      <td>2.119678</td>\n",
              "      <td>0.016989</td>\n",
              "      <td>0.224533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.331662</td>\n",
              "      <td>2.647690</td>\n",
              "      <td>4.360874</td>\n",
              "      <td>9980.878023</td>\n",
              "      <td>0.938909</td>\n",
              "      <td>0.214140</td>\n",
              "      <td>2.050552</td>\n",
              "      <td>265</td>\n",
              "      <td>11.338860</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29161</th>\n",
              "      <td>1052.216667</td>\n",
              "      <td>0.001030</td>\n",
              "      <td>0.000061</td>\n",
              "      <td>-0.063343</td>\n",
              "      <td>14.384463</td>\n",
              "      <td>50.977159</td>\n",
              "      <td>-36.876617</td>\n",
              "      <td>2.980982</td>\n",
              "      <td>0.014327</td>\n",
              "      <td>0.240533</td>\n",
              "      <td>...</td>\n",
              "      <td>0.331899</td>\n",
              "      <td>2.724291</td>\n",
              "      <td>4.297333</td>\n",
              "      <td>6018.066826</td>\n",
              "      <td>0.943428</td>\n",
              "      <td>0.041343</td>\n",
              "      <td>1.425971</td>\n",
              "      <td>146</td>\n",
              "      <td>5.661561</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29162 rows × 58 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-23633480-9eb6-4d95-95c5-e155a2b64ffd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-23633480-9eb6-4d95-95c5-e155a2b64ffd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-23633480-9eb6-4d95-95c5-e155a2b64ffd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-98b15fb7-c994-4b76-aaa9-23278f494ab4\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-98b15fb7-c994-4b76-aaa9-23278f494ab4')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-98b15fb7-c994-4b76-aaa9-23278f494ab4 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "               ZCR     MEANt      VARt     SKEWt      KURTt       LEQt  \\\n",
              "0      1764.416667  0.000781  0.000002  0.131073   4.761340  36.457276   \n",
              "1      1816.266667 -0.000061  0.000004  0.154423   5.075730  38.797116   \n",
              "2      2054.350000  0.000394  0.000002  0.096852   8.235647  37.209411   \n",
              "3      1430.466667  0.000247  0.000016  0.295968  19.141701  44.954948   \n",
              "4      1308.400000 -0.001215  0.000003  0.060765   6.980352  39.593809   \n",
              "...            ...       ...       ...       ...        ...        ...   \n",
              "29157  2664.816667  0.000966  0.000005  0.061751  15.494871  40.420251   \n",
              "29158  1991.066667  0.001092  0.000004  0.043957   3.429047  40.551362   \n",
              "29159  4111.283333  0.000574  0.000011  0.211090  14.242911  43.652024   \n",
              "29160  1752.250000  0.000544  0.000069 -0.030005   7.864743  51.411486   \n",
              "29161  1052.216667  0.001030  0.000061 -0.063343  14.384463  50.977159   \n",
              "\n",
              "            BGNt      SNRt       MED  ACTtFraction  ...  H_Havrda   H_Renyi  \\\n",
              "0     -47.705630  0.623479  0.004118      0.071467  ...  0.332788  3.207581   \n",
              "1     -46.109787  1.002794  0.004949      0.126400  ...  0.331752  2.675398   \n",
              "2     -47.877052  1.495073  0.004038      0.149867  ...  0.332604  3.062414   \n",
              "3     -44.820732  4.823176  0.005741      0.324267  ...  0.327815  2.050577   \n",
              "4     -46.251354  1.310539  0.004869      0.166400  ...  0.331297  2.548900   \n",
              "...          ...       ...       ...           ...  ...       ...       ...   \n",
              "29157 -44.081135  1.151237  0.006251      0.085867  ...  0.333277  4.343159   \n",
              "29158 -43.806730  0.529841  0.006452      0.046400  ...  0.332787  3.206599   \n",
              "29159 -43.533936  3.114562  0.006657      0.232000  ...  0.332504  2.998246   \n",
              "29160 -35.396584  2.119678  0.016989      0.224533  ...  0.331662  2.647690   \n",
              "29161 -36.876617  2.980982  0.014327      0.240533  ...  0.331899  2.724291   \n",
              "\n",
              "       H_pairedShannon       H_gamma  H_GiniSimpson      RAOQ       AGI  \\\n",
              "0             5.321909  23125.967137       0.970291  0.252875  1.213142   \n",
              "1             4.682315  13875.470578       0.946628  0.134986  1.235006   \n",
              "2             5.068941  17938.211022       0.964771  0.181781  1.225285   \n",
              "3             3.741928   4689.881419       0.891058  0.032337  1.251943   \n",
              "4             4.722316  14745.415390       0.941337  0.147151  1.231857   \n",
              "...                ...           ...            ...       ...       ...   \n",
              "29157         6.263979  42059.466244       0.990679  0.744602  1.574344   \n",
              "29158         5.445871  25623.385626       0.971321  0.335342  1.310117   \n",
              "29159         5.563157  33670.527993       0.966200  0.835676  2.200941   \n",
              "29160         4.360874   9980.878023       0.938909  0.214140  2.050552   \n",
              "29161         4.297333   6018.066826       0.943428  0.041343  1.425971   \n",
              "\n",
              "       ROItotal   ROIcover  label  \n",
              "0            58   1.350616     00  \n",
              "1           135   2.326345     00  \n",
              "2            56   2.235776     00  \n",
              "3            52   5.205276     00  \n",
              "4            85   2.485284     00  \n",
              "...         ...        ...    ...  \n",
              "29157       367   6.982161     11  \n",
              "29158       178   3.861851     11  \n",
              "29159       254  16.800731     11  \n",
              "29160       265  11.338860     11  \n",
              "29161       146   5.661561     11  \n",
              "\n",
              "[29162 rows x 58 columns]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_data_with_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl9he-j_G_Yo"
      },
      "source": [
        "## 2. Ségrégation temporelle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELHZz0NNHKHm"
      },
      "source": [
        "### a) Création des .csv pour les ensembles de test et de train (NE PAS LANCER SUR COLAB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jBPrVjKKX_A"
      },
      "source": [
        "Idée :\n",
        "\n",
        "1 dossier : 00h - 05h<br>\n",
        "1 dossier : 06h - 11h<br>\n",
        "1 dossier : 12h - 17h<br>\n",
        "1 dossier : 18h - 23h<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "sOPNFEVhHLDx",
        "outputId": "f3f9ce5b-ed4a-48ae-b91b-e0e900d038ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_csv = pd.read_csv('../Valeurs_acoustiques/concatenated_acoustic_indices.csv')\n",
        "df_test_sets = []\n",
        "df_train_sets = []\n",
        "\n",
        "# Créer l'ensemble des plages horaires\n",
        "list_aux = list(range(24))\n",
        "# Regrouper les éléments par 6\n",
        "list_plages_horaires = [list_aux[i:i+6] for i in range(0, len(list_aux), 6)]\n",
        "\n",
        "print(list_plages_horaires)\n",
        "\n",
        "# Créer les dataframes pour test et train pour la ségrégation temporelle\n",
        "for plage_horaire in list_plages_horaires:\n",
        "    df_test = pd.DataFrame(columns=['file_name', 'station_name',\t'ZCR', 'MEANt', 'VARt',\t'SKEWt', 'KURTt', 'LEQt', 'BGNt', 'SNRt', 'MED', 'Ht', 'ACTtFraction', 'ACTtCount', 'ACTtMean', 'EVNtFraction', 'EVNtMean', 'EVNtCount', 'MEANf', 'VARf', 'SKEWf', 'KURTf', 'NBPEAKS', 'LEQf', 'ENRf', 'BGNf', 'SNRf', 'Hf', 'EAS', 'ECU', 'ECV', 'EPS', 'EPS_KURT', 'EPS_SKEW', 'ACI', 'NDSI', 'rBA', 'AnthroEnergy', 'BioEnergy', 'BI', 'ROU', 'ADI', 'AEI', 'LFC', 'MFC', 'HFC', 'ACTspFract', 'ACTspCount', 'ACTspMean', 'EVNspFract', 'EVNspMean', 'EVNspCount', 'TFSD', 'H_Havrda', 'H_Renyi', 'H_pairedShannon', 'H_gamma', 'H_GiniSimpson', 'RAOQ', 'AGI', 'ROItotal', 'ROIcover'])\n",
        "    df_train = pd.DataFrame(columns=['file_name', 'station_name',\t'ZCR', 'MEANt', 'VARt',\t'SKEWt', 'KURTt', 'LEQt', 'BGNt', 'SNRt', 'MED', 'Ht', 'ACTtFraction', 'ACTtCount', 'ACTtMean', 'EVNtFraction', 'EVNtMean', 'EVNtCount', 'MEANf', 'VARf', 'SKEWf', 'KURTf', 'NBPEAKS', 'LEQf', 'ENRf', 'BGNf', 'SNRf', 'Hf', 'EAS', 'ECU', 'ECV', 'EPS', 'EPS_KURT', 'EPS_SKEW', 'ACI', 'NDSI', 'rBA', 'AnthroEnergy', 'BioEnergy', 'BI', 'ROU', 'ADI', 'AEI', 'LFC', 'MFC', 'HFC', 'ACTspFract', 'ACTspCount', 'ACTspMean', 'EVNspFract', 'EVNspMean', 'EVNspCount', 'TFSD', 'H_Havrda', 'H_Renyi', 'H_pairedShannon', 'H_gamma', 'H_GiniSimpson', 'RAOQ', 'AGI', 'ROItotal', 'ROIcover'])\n",
        "    for index, row in df_csv.iterrows():\n",
        "        file_name_parts = row['file_name'].split('_')\n",
        "        horaire = file_name_parts[2]\n",
        "        heure = horaire[:2]\n",
        "\n",
        "        if int(heure) in plage_horaire:\n",
        "            df_test = df_test._append(row, ignore_index=True)\n",
        "        else:\n",
        "            df_train = df_train._append(row, ignore_index=True)\n",
        "\n",
        "    df_test_sets += [df_test]\n",
        "    df_train_sets += [df_train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0GugAYF4OxG",
        "outputId": "17edbf4f-9208-4f06-a8a7-ca5ac2faec04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22891 + 7658 = 30549\n",
            "23029 + 7520 = 30549\n",
            "22926 + 7623 = 30549\n",
            "22801 + 7748 = 30549\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "for k in range(len(list_plages_horaires)):\n",
        "  print(f\"{len(df_train_sets[k])} + {len(df_test_sets[k])} = {len(df_train_sets[k]) + len(df_test_sets[k])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xngmT7BkmdK3"
      },
      "outputs": [],
      "source": [
        "# Fonction qui retourne un nom pour une plage horaire donnée\n",
        "def to_string(plage_horaire):\n",
        "    name_str = \"\"\n",
        "    for elt in plage_horaire:\n",
        "        name_str += str(elt)+\"_\"\n",
        "\n",
        "    return name_str[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1INXnxV6C49"
      },
      "outputs": [],
      "source": [
        "# Créer les .csv\n",
        "\n",
        "import os\n",
        "\n",
        "# Déplacer vers un dossier spécifique\n",
        "nouveau_dossier = \"../output_csv/cross_validation_temporal\"\n",
        "os.chdir(nouveau_dossier)\n",
        "\n",
        "for i in range(len(list_plages_horaires)):\n",
        "    plage_horaire = list_plages_horaires[i]\n",
        "    nom_plage_horaire = to_string(plage_horaire)\n",
        "\n",
        "    os.makedirs(nom_plage_horaire, exist_ok=True)\n",
        "\n",
        "    path_test = nom_plage_horaire+\"/\" + nom_plage_horaire + \"_test.csv\"\n",
        "    path_train = nom_plage_horaire+\"/\" + nom_plage_horaire + \"_train.csv\"\n",
        "\n",
        "    df_test_sets[i].to_csv(path_test, index=False)\n",
        "    df_train_sets[i].to_csv(path_train, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Tests sur différents modèles (A LANCER SUR COLAB)"
      ],
      "metadata": {
        "id": "P4uAwbMgqDVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "/!\\ Lancez les premières cellules de la sous-partie b) de la partie 1. avant"
      ],
      "metadata": {
        "id": "KlikqyZ1qwxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Chemin vers le répertoire contenant les dossiers de données sur Google Drive\n",
        "data_directory = \"/content/gdrive/MyDrive/ListenToTheWild/cross_validation_temporal\"\n",
        "\n",
        "# Liste des dossiers dans le répertoire\n",
        "directories = os.listdir(data_directory)\n",
        "\n",
        "rf_mean_acc = 0\n",
        "mlp_mean_acc = 0\n",
        "gb_mean_acc = 0\n",
        "# Boucle sur chaque dossier\n",
        "for directory in directories:\n",
        "  # Chemin vers le dossier contenant les fichiers de train/test\n",
        "  directory_path = os.path.join(data_directory, directory)\n",
        "\n",
        "  # Charger les données d'entraînement\n",
        "  train_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_train.csv\"))\n",
        "  nb_rows_train = train_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  train_data_with_labels = add_labels(train_data)\n",
        "  # Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "  train_data_with_labels = train_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "  # Pour supprimer les NaN\n",
        "  train_data_with_labels = train_data_with_labels.drop(['Ht', 'ACTtMean', 'TFSD'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_train = train_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_train = train_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Charger les données de test\n",
        "  test_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_test.csv\"))\n",
        "  nb_rows_test = test_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  test_data_with_labels = add_labels(test_data)\n",
        "  # Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "  test_data_with_labels = test_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "  # Pour supprimer les NaN\n",
        "  test_data_with_labels = test_data_with_labels.drop(['Ht', 'ACTtMean', 'TFSD'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_test = test_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_test = test_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Créer les modèles\n",
        "  rf_model = RandomForestClassifier()\n",
        "  mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500)\n",
        "  gb_model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=3)\n",
        "\n",
        "  # Effectuer les validations croisées personnalisées\n",
        "  rf_accuracy = custom_cross_validation(rf_model, X_train, y_train, X_test, y_test)\n",
        "  mlp_accuracy = custom_cross_validation(mlp_model, X_train, y_train, X_test, y_test)\n",
        "  gb_accuracy = custom_cross_validation(gb_model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "  # Calculer la moyenne des précisions\n",
        "  mean_accuracy = (rf_accuracy + mlp_accuracy + gb_accuracy)/3\n",
        "\n",
        "  # Ajouter les valeurs pour le calcul des moyennes\n",
        "  rf_mean_acc += rf_accuracy\n",
        "  mlp_mean_acc += mlp_accuracy\n",
        "  gb_mean_acc += gb_accuracy\n",
        "\n",
        "  # Calculer les pourcentages des ensembles\n",
        "  per_train_set = nb_rows_train / (nb_rows_train + nb_rows_test)\n",
        "  per_test_set = nb_rows_test / (nb_rows_train + nb_rows_test)\n",
        "\n",
        "  # Afficher les précisions sur l'ensemble de test\n",
        "  print(f\"Dossier {directory} (train : {round(per_train_set*100, 2)}% / test : {round(per_test_set*100, 2)}%) :\")\n",
        "  print(f\"Précision sur l'ensemble de test avec RF : {round(rf_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec MLP : {round(mlp_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec GB : {round(gb_accuracy, 2)}\")\n",
        "  print(f\"Moyenne des précisions : {round(mean_accuracy, 2)}\")\n",
        "  print()\n",
        "\n",
        "print(\"=======================================================================\")\n",
        "print()\n",
        "\n",
        "# Afficher les moyennes des précisions par modèle\n",
        "nb_dir = len(directories)\n",
        "print(f\"Moyenne des précisions avec RF : {round(rf_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec MLP : {round(mlp_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec GB : {round(gb_mean_acc/nb_dir, 2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBBgRFbNqumy",
        "outputId": "0e43db13-a742-41c4-ffa3-cea8f8d53e4f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier 0_1_2_3_4_5 (train : 74.93% / test : 25.07%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.65\n",
            "Précision sur l'ensemble de test avec MLP : 0.35\n",
            "Précision sur l'ensemble de test avec GB : 0.51\n",
            "Moyenne des précisions : 0.5\n",
            "\n",
            "Dossier 18_19_20_21_22_23 (train : 74.64% / test : 25.36%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.65\n",
            "Précision sur l'ensemble de test avec MLP : 0.32\n",
            "Précision sur l'ensemble de test avec GB : 0.53\n",
            "Moyenne des précisions : 0.5\n",
            "\n",
            "Dossier 12_13_14_15_16_17 (train : 75.05% / test : 24.95%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.62\n",
            "Précision sur l'ensemble de test avec MLP : 0.38\n",
            "Précision sur l'ensemble de test avec GB : 0.51\n",
            "Moyenne des précisions : 0.51\n",
            "\n",
            "Dossier 6_7_8_9_10_11 (train : 75.38% / test : 24.62%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.62\n",
            "Précision sur l'ensemble de test avec MLP : 0.37\n",
            "Précision sur l'ensemble de test avec GB : 0.52\n",
            "Moyenne des précisions : 0.5\n",
            "\n",
            "=======================================================================\n",
            "\n",
            "Moyenne des précisions avec RF : 0.63\n",
            "Moyenne des précisions avec MLP : 0.35\n",
            "Moyenne des précisions avec GB : 0.52\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}