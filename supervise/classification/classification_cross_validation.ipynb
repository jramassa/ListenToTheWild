{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTYZLuAEfqIg"
      },
      "source": [
        "# Classification cross validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bnGDveyfqIi"
      },
      "source": [
        "## 1. Ségrégation spatiale"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQLXY-I9fqIi"
      },
      "source": [
        "### a) Création des .csv pour les ensembles de test et de train (NE PAS LANCER SUR COLAB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrtbKmnDfqIj",
        "outputId": "4feee2ca-0bc5-40eb-9a00-ad56c6dbeddb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:2: DeprecationWarning: \n",
            "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
            "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
            "but was not found to be installed on your system.\n",
            "If this would cause problems for you,\n",
            "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
            "        \n",
            "  import pandas as pd\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['Antras_Isard', 'Appy_Etang_dAppy', 'Arrien_Pic_Midi_Bordes', 'Ascou_Pailheres', 'Aston_Plateau_de_Beille', 'Aulus_Turon_Rose', 'Bestiac_Trimouns', 'Bethmale_Ayet', 'Bethmale_Eychelle', 'Bonac_Arech', 'Bonac_Orle', 'Couflens_Pouill', 'Couflens_SaubÃ©', 'FormiguÃ¨res_Serra_dels_Alarbs', 'GestiÃ¨s_Col_du_Sasc', 'GestiÃ¨s_Le_Clot', 'Goulier_Val_de_Sos', 'Lercoul_Col_de_Grail', 'Les_Angles_Puig_del_Pam', 'Les_Angles_Roc_dAude', 'Merens_Comte', 'Miglos_Pla_de_Montcamp', 'Mijanes_Estagnet', 'Mijanes_Trabesses', 'Montferrier_Mont_dOlmes', 'Montsegur_Frau', 'MontsÃ©gur_Soularac', 'Orgeix_Coume', 'Orlu_RNCFS', 'Saint-Lary_Herbe_Soulette', 'Seix_Col_de_Pause', 'Seix_Pic_de_Montbuou', 'Sentein_Eylie', 'Ustou_Col_dEscots', 'Ustou_Guzet-Neige', 'ValcebollÃ¨re_Pla_des_Salines']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:31: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16832\\3860246743.py:33: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "df_csv = pd.read_csv('../Valeurs_acoustiques/concatenated_acoustic_indices.csv')\n",
        "df_test_sets = []\n",
        "df_train_sets = []\n",
        "\n",
        "# Créer l'ensemble des stations\n",
        "with open('../Valeurs_acoustiques/concatenated_acoustic_indices.csv', mode='r', encoding='utf-8') as csv_file:\n",
        "    csv_reader = csv.DictReader(csv_file)\n",
        "\n",
        "    list_stations = []\n",
        "    for row in csv_reader:\n",
        "        station_name_parts = row['station_name'].split('/')\n",
        "        station_name = station_name_parts[1]\n",
        "        list_stations.append(station_name)\n",
        "\n",
        "    set_stations = sorted(set(list_stations)) # sorted pour ordre alphabétique\n",
        "\n",
        "print(set_stations)\n",
        "\n",
        "# Créer les dataframes pour test et train pour la ségrégation spatiale\n",
        "for station in set_stations:\n",
        "    df_test = pd.DataFrame(columns=['file_name', 'station_name',\t'ZCR', 'MEANt', 'VARt',\t'SKEWt', 'KURTt', 'LEQt', 'BGNt', 'SNRt', 'MED', 'Ht', 'ACTtFraction', 'ACTtCount', 'ACTtMean', 'EVNtFraction', 'EVNtMean', 'EVNtCount', 'MEANf', 'VARf', 'SKEWf', 'KURTf', 'NBPEAKS', 'LEQf', 'ENRf', 'BGNf', 'SNRf', 'Hf', 'EAS', 'ECU', 'ECV', 'EPS', 'EPS_KURT', 'EPS_SKEW', 'ACI', 'NDSI', 'rBA', 'AnthroEnergy', 'BioEnergy', 'BI', 'ROU', 'ADI', 'AEI', 'LFC', 'MFC', 'HFC', 'ACTspFract', 'ACTspCount', 'ACTspMean', 'EVNspFract', 'EVNspMean', 'EVNspCount', 'TFSD', 'H_Havrda', 'H_Renyi', 'H_pairedShannon', 'H_gamma', 'H_GiniSimpson', 'RAOQ', 'AGI', 'ROItotal', 'ROIcover'])\n",
        "    df_train = pd.DataFrame(columns=['file_name', 'station_name',\t'ZCR', 'MEANt', 'VARt',\t'SKEWt', 'KURTt', 'LEQt', 'BGNt', 'SNRt', 'MED', 'Ht', 'ACTtFraction', 'ACTtCount', 'ACTtMean', 'EVNtFraction', 'EVNtMean', 'EVNtCount', 'MEANf', 'VARf', 'SKEWf', 'KURTf', 'NBPEAKS', 'LEQf', 'ENRf', 'BGNf', 'SNRf', 'Hf', 'EAS', 'ECU', 'ECV', 'EPS', 'EPS_KURT', 'EPS_SKEW', 'ACI', 'NDSI', 'rBA', 'AnthroEnergy', 'BioEnergy', 'BI', 'ROU', 'ADI', 'AEI', 'LFC', 'MFC', 'HFC', 'ACTspFract', 'ACTspCount', 'ACTspMean', 'EVNspFract', 'EVNspMean', 'EVNspCount', 'TFSD', 'H_Havrda', 'H_Renyi', 'H_pairedShannon', 'H_gamma', 'H_GiniSimpson', 'RAOQ', 'AGI', 'ROItotal', 'ROIcover'])\n",
        "    for index, row in df_csv.iterrows():\n",
        "        station_name_parts = row['station_name'].split('/')\n",
        "        station_name = station_name_parts[1]\n",
        "\n",
        "        if station_name == station:\n",
        "            df_test = df_test._append(row, ignore_index=True)\n",
        "        else:\n",
        "            df_train = df_train._append(row, ignore_index=True)\n",
        "\n",
        "    df_test_sets += [df_test]\n",
        "    df_train_sets += [df_train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96rdVnVmfqIk",
        "outputId": "9a94275b-0202-4e67-ff5d-4b6032a0049f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "30549\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "print(len(df_test_sets[1]) + len(df_train_sets[1]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elVTAR-kfqIl"
      },
      "outputs": [],
      "source": [
        "# Créer les .csv\n",
        "\n",
        "import os\n",
        "\n",
        "# Déplacer vers un dossier spécifique\n",
        "nouveau_dossier = \"../output_csv/cross_validation_spatial\"\n",
        "os.chdir(nouveau_dossier)\n",
        "\n",
        "for i in range(len(set_stations)):\n",
        "    os.makedirs(set_stations[i], exist_ok=True)\n",
        "\n",
        "    path_test = set_stations[i]+\"/\" + set_stations[i] + \"_test.csv\"\n",
        "    path_train = set_stations[i]+\"/\" + set_stations[i] + \"_train.csv\"\n",
        "\n",
        "    df_test_sets[i].to_csv(path_test, index=False)\n",
        "    df_train_sets[i].to_csv(path_train, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57mmZlxufqIl"
      },
      "source": [
        "### b) Tests sur différents modèles (A LANCER SUR COLAB)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRfJ7QB6fw2Q",
        "outputId": "5299f6c5-b987-401f-8271-a6b56d08e308"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "c8KaHzptxq36"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def separate_integers_letters(string):\n",
        "    integers = ''.join(re.findall(r'\\d+', string))\n",
        "    letters = ''.join(re.findall(r'[a-zA-Z]+', string))\n",
        "    return integers, letters"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dico_encodage = {'E_Bleu': 1, 'E_Rouge': 2, 'L_Bleu': 3, 'L_Rouge': 4}\n",
        "print(dico_encodage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkBXv8_UWvpK",
        "outputId": "feab8df7-858b-4a4c-86e8-7bb3d5f0cdad"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'E_Bleu': 1, 'E_Rouge': 2, 'L_Bleu': 3, 'L_Rouge': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V8O_afOTo0aB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def add_labels(df):\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    station_name_parts = row['station_name'].split('/')\n",
        "    position_dynamique = station_name_parts[2]\n",
        "    position_dynamique_parts = position_dynamique.split('_')\n",
        "    _, position = separate_integers_letters(position_dynamique_parts[1])\n",
        "    dynamique = position_dynamique_parts[2]\n",
        "\n",
        "    position_dynamique = position + '_' + dynamique\n",
        "\n",
        "    df.loc[index, 'label'] = dico_encodage[position_dynamique]\n",
        "\n",
        "  return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "GlEJoORrhXhE"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def custom_cross_validation(model, X_train, y_train, X_test, y_test):\n",
        "    # Entraîner le modèle sur l'ensemble de données d'entraînement\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prédire les étiquettes sur l'ensemble de test\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculer la précision du modèle\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "glOVwpTxfqIl",
        "outputId": "652bb132-561f-4a8f-888c-c7fae0b80c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier Antras_Isard (train : 95.46% / test : 4.54%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.29\n",
            "Précision sur l'ensemble de test avec MLP : 0.2\n",
            "Précision sur l'ensemble de test avec GB : 0.31\n",
            "Moyenne des précisions : 0.27\n",
            "\n",
            "Dossier Appy_Etang_dAppy (train : 97.81% / test : 2.19%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.3\n",
            "Précision sur l'ensemble de test avec MLP : 0.26\n",
            "Précision sur l'ensemble de test avec GB : 0.21\n",
            "Moyenne des précisions : 0.26\n",
            "\n",
            "Dossier Arrien_Pic_Midi_Bordes (train : 95.68% / test : 4.32%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.26\n",
            "Précision sur l'ensemble de test avec GB : 0.36\n",
            "Moyenne des précisions : 0.32\n",
            "\n",
            "Dossier Ascou_Pailheres (train : 98.02% / test : 1.98%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.34\n",
            "Précision sur l'ensemble de test avec MLP : 0.25\n",
            "Précision sur l'ensemble de test avec GB : 0.33\n",
            "Moyenne des précisions : 0.31\n",
            "\n",
            "Dossier Aston_Plateau_de_Beille (train : 98.14% / test : 1.86%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.36\n",
            "Précision sur l'ensemble de test avec MLP : 0.3\n",
            "Précision sur l'ensemble de test avec GB : 0.38\n",
            "Moyenne des précisions : 0.35\n",
            "\n",
            "Dossier Aulus_Turon_Rose (train : 97.8% / test : 2.2%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.42\n",
            "Précision sur l'ensemble de test avec MLP : 0.25\n",
            "Précision sur l'ensemble de test avec GB : 0.44\n",
            "Moyenne des précisions : 0.37\n",
            "\n",
            "Dossier Bestiac_Trimouns (train : 97.24% / test : 2.76%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.31\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.34\n",
            "\n",
            "Dossier Bethmale_Ayet (train : 99.06% / test : 0.94%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.41\n",
            "Précision sur l'ensemble de test avec MLP : 0.28\n",
            "Précision sur l'ensemble de test avec GB : 0.37\n",
            "Moyenne des précisions : 0.35\n",
            "\n",
            "Dossier Bethmale_Eychelle (train : 98.1% / test : 1.9%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.3\n",
            "Précision sur l'ensemble de test avec MLP : 0.27\n",
            "Précision sur l'ensemble de test avec GB : 0.39\n",
            "Moyenne des précisions : 0.32\n",
            "\n",
            "Dossier Bonac_Arech (train : 97.48% / test : 2.52%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.38\n",
            "Précision sur l'ensemble de test avec MLP : 0.22\n",
            "Précision sur l'ensemble de test avec GB : 0.38\n",
            "Moyenne des précisions : 0.33\n",
            "\n",
            "Dossier Bonac_Orle (train : 95.61% / test : 4.39%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.2\n",
            "Précision sur l'ensemble de test avec MLP : 0.22\n",
            "Précision sur l'ensemble de test avec GB : 0.22\n",
            "Moyenne des précisions : 0.22\n",
            "\n",
            "Dossier Couflens_Pouill (train : 99.08% / test : 0.92%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.31\n",
            "Précision sur l'ensemble de test avec MLP : 0.26\n",
            "Précision sur l'ensemble de test avec GB : 0.27\n",
            "Moyenne des précisions : 0.28\n",
            "\n",
            "Dossier Couflens_Saubé (train : 99.34% / test : 0.66%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.39\n",
            "Précision sur l'ensemble de test avec MLP : 0.19\n",
            "Précision sur l'ensemble de test avec GB : 0.25\n",
            "Moyenne des précisions : 0.28\n",
            "\n",
            "Dossier Formiguères_Serra_dels_Alarbs (train : 95.7% / test : 4.3%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.25\n",
            "Précision sur l'ensemble de test avec MLP : 0.25\n",
            "Précision sur l'ensemble de test avec GB : 0.26\n",
            "Moyenne des précisions : 0.25\n",
            "\n",
            "Dossier Gestiès_Col_du_Sasc (train : 98.58% / test : 1.42%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.26\n",
            "Précision sur l'ensemble de test avec MLP : 0.33\n",
            "Précision sur l'ensemble de test avec GB : 0.27\n",
            "Moyenne des précisions : 0.28\n",
            "\n",
            "Dossier Gestiès_Le_Clot (train : 97.82% / test : 2.18%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.4\n",
            "Précision sur l'ensemble de test avec MLP : 0.3\n",
            "Précision sur l'ensemble de test avec GB : 0.41\n",
            "Moyenne des précisions : 0.37\n",
            "\n",
            "Dossier Goulier_Val_de_Sos (train : 98.19% / test : 1.81%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.37\n",
            "Précision sur l'ensemble de test avec MLP : 0.35\n",
            "Précision sur l'ensemble de test avec GB : 0.25\n",
            "Moyenne des précisions : 0.32\n",
            "\n",
            "Dossier Lercoul_Col_de_Grail (train : 98.14% / test : 1.86%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.41\n",
            "Précision sur l'ensemble de test avec MLP : 0.36\n",
            "Précision sur l'ensemble de test avec GB : 0.41\n",
            "Moyenne des précisions : 0.39\n",
            "\n",
            "Dossier Les_Angles_Puig_del_Pam (train : 95.33% / test : 4.67%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.22\n",
            "Précision sur l'ensemble de test avec MLP : 0.25\n",
            "Précision sur l'ensemble de test avec GB : 0.21\n",
            "Moyenne des précisions : 0.23\n",
            "\n",
            "Dossier Les_Angles_Roc_dAude (train : 95.42% / test : 4.58%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.26\n",
            "Précision sur l'ensemble de test avec MLP : 0.33\n",
            "Précision sur l'ensemble de test avec GB : 0.2\n",
            "Moyenne des précisions : 0.26\n",
            "\n",
            "Dossier Merens_Comte (train : 95.99% / test : 4.01%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.12\n",
            "Précision sur l'ensemble de test avec MLP : 0.14\n",
            "Précision sur l'ensemble de test avec GB : 0.12\n",
            "Moyenne des précisions : 0.13\n",
            "\n",
            "Dossier Miglos_Pla_de_Montcamp (train : 98.14% / test : 1.86%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.32\n",
            "Précision sur l'ensemble de test avec MLP : 0.34\n",
            "Précision sur l'ensemble de test avec GB : 0.35\n",
            "Moyenne des précisions : 0.34\n",
            "\n",
            "Dossier Mijanes_Estagnet (train : 96.3% / test : 3.7%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.38\n",
            "Précision sur l'ensemble de test avec MLP : 0.3\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.34\n",
            "\n",
            "Dossier Mijanes_Trabesses (train : 97.3% / test : 2.7%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.29\n",
            "Précision sur l'ensemble de test avec MLP : 0.22\n",
            "Précision sur l'ensemble de test avec GB : 0.2\n",
            "Moyenne des précisions : 0.24\n",
            "\n",
            "Dossier Montferrier_Mont_dOlmes (train : 97.46% / test : 2.54%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.3\n",
            "Précision sur l'ensemble de test avec MLP : 0.27\n",
            "Précision sur l'ensemble de test avec GB : 0.31\n",
            "Moyenne des précisions : 0.29\n",
            "\n",
            "Dossier Montsegur_Frau (train : 98.88% / test : 1.12%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.17\n",
            "Précision sur l'ensemble de test avec MLP : 0.15\n",
            "Précision sur l'ensemble de test avec GB : 0.17\n",
            "Moyenne des précisions : 0.17\n",
            "\n",
            "Dossier Montségur_Soularac (train : 94.78% / test : 5.22%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.48\n",
            "Précision sur l'ensemble de test avec GB : 0.47\n",
            "Moyenne des précisions : 0.43\n",
            "\n",
            "Dossier Orgeix_Coume (train : 97.55% / test : 2.45%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.48\n",
            "Précision sur l'ensemble de test avec MLP : 0.41\n",
            "Précision sur l'ensemble de test avec GB : 0.37\n",
            "Moyenne des précisions : 0.42\n",
            "\n",
            "Dossier Orlu_RNCFS (train : 96.31% / test : 3.69%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.24\n",
            "Précision sur l'ensemble de test avec MLP : 0.1\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.23\n",
            "\n",
            "Dossier Saint-Lary_Herbe_Soulette (train : 98.02% / test : 1.98%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.4\n",
            "Précision sur l'ensemble de test avec MLP : 0.17\n",
            "Précision sur l'ensemble de test avec GB : 0.41\n",
            "Moyenne des précisions : 0.33\n",
            "\n",
            "Dossier Seix_Col_de_Pause (train : 98.23% / test : 1.77%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.34\n",
            "Précision sur l'ensemble de test avec MLP : 0.23\n",
            "Précision sur l'ensemble de test avec GB : 0.4\n",
            "Moyenne des précisions : 0.32\n",
            "\n",
            "Dossier Seix_Pic_de_Montbuou (train : 95.73% / test : 4.27%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.29\n",
            "Précision sur l'ensemble de test avec MLP : 0.31\n",
            "Précision sur l'ensemble de test avec GB : 0.29\n",
            "Moyenne des précisions : 0.3\n",
            "\n",
            "Dossier Sentein_Eylie (train : 95.89% / test : 4.11%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.45\n",
            "Précision sur l'ensemble de test avec GB : 0.44\n",
            "Moyenne des précisions : 0.42\n",
            "\n",
            "Dossier Ustou_Col_dEscots (train : 95.93% / test : 4.07%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.14\n",
            "Précision sur l'ensemble de test avec MLP : 0.22\n",
            "Précision sur l'ensemble de test avec GB : 0.14\n",
            "Moyenne des précisions : 0.17\n",
            "\n",
            "Dossier Ustou_Guzet-Neige (train : 98.76% / test : 1.24%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.49\n",
            "Précision sur l'ensemble de test avec MLP : 0.06\n",
            "Précision sur l'ensemble de test avec GB : 0.57\n",
            "Moyenne des précisions : 0.37\n",
            "\n",
            "Dossier Valcebollère_Pla_des_Salines (train : 96.73% / test : 3.27%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.12\n",
            "Précision sur l'ensemble de test avec MLP : 0.12\n",
            "Précision sur l'ensemble de test avec GB : 0.16\n",
            "Moyenne des précisions : 0.14\n",
            "\n",
            "=======================================================================\n",
            "\n",
            "Moyenne des précisions avec RF : 0.32\n",
            "Moyenne des précisions avec MLP : 0.26\n",
            "Moyenne des précisions avec GB : 0.31\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Chemin vers le répertoire contenant les dossiers de données sur Google Drive\n",
        "data_directory = \"/content/gdrive/MyDrive/ListenToTheWild/cross_validation_spatial\"\n",
        "\n",
        "# Liste des dossiers dans le répertoire\n",
        "directories = sorted(os.listdir(data_directory))\n",
        "\n",
        "rf_mean_acc = 0\n",
        "mlp_mean_acc = 0\n",
        "gb_mean_acc = 0\n",
        "# Boucle sur chaque dossier\n",
        "for directory in directories:\n",
        "  # Chemin vers le dossier contenant les fichiers de train/test\n",
        "  directory_path = os.path.join(data_directory, directory)\n",
        "\n",
        "  # Charger les données d'entraînement\n",
        "  train_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_train.csv\"))\n",
        "  nb_rows_train = train_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  train_data_with_labels = add_labels(train_data)\n",
        "  # Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "  train_data_with_labels = train_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "  # Pour supprimer les NaN\n",
        "  train_data_with_labels = train_data_with_labels.drop(['Ht', 'ACTtMean', 'TFSD'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_train = train_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_train = train_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Charger les données de test\n",
        "  test_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_test.csv\"))\n",
        "  nb_rows_test = test_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  test_data_with_labels = add_labels(test_data)\n",
        "  # Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "  test_data_with_labels = test_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "  # Pour supprimer les NaN\n",
        "  test_data_with_labels = test_data_with_labels.drop(['Ht', 'ACTtMean', 'TFSD'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_test = test_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_test = test_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Créer les modèles\n",
        "  rf_model = RandomForestClassifier()\n",
        "  mlp_model = MLPClassifier()\n",
        "  gb_model = GradientBoostingClassifier()\n",
        "\n",
        "  # Effectuer les validations croisées personnalisées\n",
        "  rf_accuracy = custom_cross_validation(rf_model, X_train, y_train, X_test, y_test)\n",
        "  mlp_accuracy = custom_cross_validation(mlp_model, X_train, y_train, X_test, y_test)\n",
        "  gb_accuracy = custom_cross_validation(gb_model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "  # Calculer la moyenne des précisions\n",
        "  mean_accuracy = (rf_accuracy + mlp_accuracy + gb_accuracy)/3\n",
        "\n",
        "  # Ajouter les valeurs pour le calcul des moyennes\n",
        "  rf_mean_acc += rf_accuracy\n",
        "  mlp_mean_acc += mlp_accuracy\n",
        "  gb_mean_acc += gb_accuracy\n",
        "\n",
        "  # Calculer les pourcentages des ensembles\n",
        "  per_train_set = nb_rows_train / (nb_rows_train + nb_rows_test)\n",
        "  per_test_set = nb_rows_test / (nb_rows_train + nb_rows_test)\n",
        "\n",
        "  # Afficher les précisions sur l'ensemble de test\n",
        "  print(f\"Dossier {directory} (train : {round(per_train_set*100, 2)}% / test : {round(per_test_set*100, 2)}%) :\")\n",
        "  print(f\"Précision sur l'ensemble de test avec RF : {round(rf_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec MLP : {round(mlp_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec GB : {round(gb_accuracy, 2)}\")\n",
        "  print(f\"Moyenne des précisions : {round(mean_accuracy, 2)}\")\n",
        "  print()\n",
        "\n",
        "print(\"=======================================================================\")\n",
        "print()\n",
        "\n",
        "# Afficher les moyennes des précisions par modèle\n",
        "nb_dir = len(directories)\n",
        "print(f\"Moyenne des précisions avec RF : {round(rf_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec MLP : {round(mlp_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec GB : {round(gb_mean_acc/nb_dir, 2)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl9he-j_G_Yo"
      },
      "source": [
        "## 2. Ségrégation temporelle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELHZz0NNHKHm"
      },
      "source": [
        "### a) Création des .csv pour les ensembles de test et de train (NE PAS LANCER SUR COLAB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4jBPrVjKKX_A"
      },
      "source": [
        "Idée :\n",
        "\n",
        "1 dossier : 00h - 05h<br>\n",
        "1 dossier : 06h - 11h<br>\n",
        "1 dossier : 12h - 17h<br>\n",
        "1 dossier : 18h - 23h<br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "sOPNFEVhHLDx",
        "outputId": "f3f9ce5b-ed4a-48ae-b91b-e0e900d038ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0, 1, 2, 3, 4, 5], [6, 7, 8, 9, 10, 11], [12, 13, 14, 15, 16, 17], [18, 19, 20, 21, 22, 23]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:26: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_train = df_train._append(row, ignore_index=True)\n",
            "C:\\Users\\Jonas\\AppData\\Local\\Temp\\ipykernel_16540\\1720490048.py:24: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  df_test = df_test._append(row, ignore_index=True)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_csv = pd.read_csv('../Valeurs_acoustiques/concatenated_acoustic_indices.csv')\n",
        "df_test_sets = []\n",
        "df_train_sets = []\n",
        "\n",
        "# Créer l'ensemble des plages horaires\n",
        "list_aux = list(range(24))\n",
        "# Regrouper les éléments par 6\n",
        "list_plages_horaires = [list_aux[i:i+6] for i in range(0, len(list_aux), 6)]\n",
        "\n",
        "print(list_plages_horaires)\n",
        "\n",
        "# Créer les dataframes pour test et train pour la ségrégation temporelle\n",
        "for plage_horaire in list_plages_horaires:\n",
        "    df_test = pd.DataFrame(columns=['file_name', 'station_name',\t'ZCR', 'MEANt', 'VARt',\t'SKEWt', 'KURTt', 'LEQt', 'BGNt', 'SNRt', 'MED', 'Ht', 'ACTtFraction', 'ACTtCount', 'ACTtMean', 'EVNtFraction', 'EVNtMean', 'EVNtCount', 'MEANf', 'VARf', 'SKEWf', 'KURTf', 'NBPEAKS', 'LEQf', 'ENRf', 'BGNf', 'SNRf', 'Hf', 'EAS', 'ECU', 'ECV', 'EPS', 'EPS_KURT', 'EPS_SKEW', 'ACI', 'NDSI', 'rBA', 'AnthroEnergy', 'BioEnergy', 'BI', 'ROU', 'ADI', 'AEI', 'LFC', 'MFC', 'HFC', 'ACTspFract', 'ACTspCount', 'ACTspMean', 'EVNspFract', 'EVNspMean', 'EVNspCount', 'TFSD', 'H_Havrda', 'H_Renyi', 'H_pairedShannon', 'H_gamma', 'H_GiniSimpson', 'RAOQ', 'AGI', 'ROItotal', 'ROIcover'])\n",
        "    df_train = pd.DataFrame(columns=['file_name', 'station_name',\t'ZCR', 'MEANt', 'VARt',\t'SKEWt', 'KURTt', 'LEQt', 'BGNt', 'SNRt', 'MED', 'Ht', 'ACTtFraction', 'ACTtCount', 'ACTtMean', 'EVNtFraction', 'EVNtMean', 'EVNtCount', 'MEANf', 'VARf', 'SKEWf', 'KURTf', 'NBPEAKS', 'LEQf', 'ENRf', 'BGNf', 'SNRf', 'Hf', 'EAS', 'ECU', 'ECV', 'EPS', 'EPS_KURT', 'EPS_SKEW', 'ACI', 'NDSI', 'rBA', 'AnthroEnergy', 'BioEnergy', 'BI', 'ROU', 'ADI', 'AEI', 'LFC', 'MFC', 'HFC', 'ACTspFract', 'ACTspCount', 'ACTspMean', 'EVNspFract', 'EVNspMean', 'EVNspCount', 'TFSD', 'H_Havrda', 'H_Renyi', 'H_pairedShannon', 'H_gamma', 'H_GiniSimpson', 'RAOQ', 'AGI', 'ROItotal', 'ROIcover'])\n",
        "    for index, row in df_csv.iterrows():\n",
        "        file_name_parts = row['file_name'].split('_')\n",
        "        horaire = file_name_parts[2]\n",
        "        heure = horaire[:2]\n",
        "\n",
        "        if int(heure) in plage_horaire:\n",
        "            df_test = df_test._append(row, ignore_index=True)\n",
        "        else:\n",
        "            df_train = df_train._append(row, ignore_index=True)\n",
        "\n",
        "    df_test_sets += [df_test]\n",
        "    df_train_sets += [df_train]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0GugAYF4OxG",
        "outputId": "17edbf4f-9208-4f06-a8a7-ca5ac2faec04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "22891 + 7658 = 30549\n",
            "23029 + 7520 = 30549\n",
            "22926 + 7623 = 30549\n",
            "22801 + 7748 = 30549\n"
          ]
        }
      ],
      "source": [
        "# Test\n",
        "for k in range(len(list_plages_horaires)):\n",
        "  print(f\"{len(df_train_sets[k])} + {len(df_test_sets[k])} = {len(df_train_sets[k]) + len(df_test_sets[k])}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xngmT7BkmdK3"
      },
      "outputs": [],
      "source": [
        "# Fonction qui retourne un nom pour une plage horaire donnée\n",
        "def to_string(plage_horaire):\n",
        "    name_str = \"\"\n",
        "    for elt in plage_horaire:\n",
        "        name_str += str(elt)+\"_\"\n",
        "\n",
        "    return name_str[:-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G1INXnxV6C49"
      },
      "outputs": [],
      "source": [
        "# Créer les .csv\n",
        "\n",
        "import os\n",
        "\n",
        "# Déplacer vers un dossier spécifique\n",
        "nouveau_dossier = \"../output_csv/cross_validation_temporal\"\n",
        "os.chdir(nouveau_dossier)\n",
        "\n",
        "for i in range(len(list_plages_horaires)):\n",
        "    plage_horaire = list_plages_horaires[i]\n",
        "    nom_plage_horaire = to_string(plage_horaire)\n",
        "\n",
        "    os.makedirs(nom_plage_horaire, exist_ok=True)\n",
        "\n",
        "    path_test = nom_plage_horaire+\"/\" + nom_plage_horaire + \"_test.csv\"\n",
        "    path_train = nom_plage_horaire+\"/\" + nom_plage_horaire + \"_train.csv\"\n",
        "\n",
        "    df_test_sets[i].to_csv(path_test, index=False)\n",
        "    df_train_sets[i].to_csv(path_train, index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Tests sur différents modèles (A LANCER SUR COLAB)"
      ],
      "metadata": {
        "id": "P4uAwbMgqDVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "/!\\ Lancez les premières cellules de la sous-partie b) de la partie 1. avant"
      ],
      "metadata": {
        "id": "KlikqyZ1qwxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Chemin vers le répertoire contenant les dossiers de données sur Google Drive\n",
        "data_directory = \"/content/gdrive/MyDrive/ListenToTheWild/cross_validation_temporal\"\n",
        "\n",
        "# Liste des dossiers dans le répertoire\n",
        "directories = os.listdir(data_directory)\n",
        "\n",
        "rf_mean_acc = 0\n",
        "mlp_mean_acc = 0\n",
        "gb_mean_acc = 0\n",
        "# Boucle sur chaque dossier\n",
        "for directory in directories:\n",
        "  # Chemin vers le dossier contenant les fichiers de train/test\n",
        "  directory_path = os.path.join(data_directory, directory)\n",
        "\n",
        "  # Charger les données d'entraînement\n",
        "  train_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_train.csv\"))\n",
        "  nb_rows_train = train_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  train_data_with_labels = add_labels(train_data)\n",
        "  # Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "  train_data_with_labels = train_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "  # Pour supprimer les NaN\n",
        "  train_data_with_labels = train_data_with_labels.drop(['Ht', 'ACTtMean', 'TFSD'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_train = train_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_train = train_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Charger les données de test\n",
        "  test_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_test.csv\"))\n",
        "  nb_rows_test = test_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  test_data_with_labels = add_labels(test_data)\n",
        "  # Supprimer les colonnes \"file_name\" et \"station_name\"\n",
        "  test_data_with_labels = test_data_with_labels.drop(['file_name', 'station_name'], axis=1)\n",
        "  # Pour supprimer les NaN\n",
        "  test_data_with_labels = test_data_with_labels.drop(['Ht', 'ACTtMean', 'TFSD'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_test = test_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_test = test_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Créer les modèles\n",
        "  rf_model = RandomForestClassifier()\n",
        "  mlp_model = MLPClassifier()\n",
        "  gb_model = GradientBoostingClassifier()\n",
        "\n",
        "  # Effectuer les validations croisées personnalisées\n",
        "  rf_accuracy = custom_cross_validation(rf_model, X_train, y_train, X_test, y_test)\n",
        "  mlp_accuracy = custom_cross_validation(mlp_model, X_train, y_train, X_test, y_test)\n",
        "  gb_accuracy = custom_cross_validation(gb_model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "  # Calculer la moyenne des précisions\n",
        "  mean_accuracy = (rf_accuracy + mlp_accuracy + gb_accuracy)/3\n",
        "\n",
        "  # Ajouter les valeurs pour le calcul des moyennes\n",
        "  rf_mean_acc += rf_accuracy\n",
        "  mlp_mean_acc += mlp_accuracy\n",
        "  gb_mean_acc += gb_accuracy\n",
        "\n",
        "  # Calculer les pourcentages des ensembles\n",
        "  per_train_set = nb_rows_train / (nb_rows_train + nb_rows_test)\n",
        "  per_test_set = nb_rows_test / (nb_rows_train + nb_rows_test)\n",
        "\n",
        "  # Afficher les précisions sur l'ensemble de test\n",
        "  print(f\"Dossier {directory} (train : {round(per_train_set*100, 2)}% / test : {round(per_test_set*100, 2)}%) :\")\n",
        "  print(f\"Précision sur l'ensemble de test avec RF : {round(rf_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec MLP : {round(mlp_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec GB : {round(gb_accuracy, 2)}\")\n",
        "  print(f\"Moyenne des précisions : {round(mean_accuracy, 2)}\")\n",
        "  print()\n",
        "\n",
        "print(\"=======================================================================\")\n",
        "print()\n",
        "\n",
        "# Afficher les moyennes des précisions par modèle\n",
        "nb_dir = len(directories)\n",
        "print(f\"Moyenne des précisions avec RF : {round(rf_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec MLP : {round(mlp_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec GB : {round(gb_mean_acc/nb_dir, 2)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBBgRFbNqumy",
        "outputId": "8cf7e6b3-5563-4e9d-acf5-add05a82cedb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier 0_1_2_3_4_5 (train : 74.93% / test : 25.07%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.65\n",
            "Précision sur l'ensemble de test avec MLP : 0.28\n",
            "Précision sur l'ensemble de test avec GB : 0.51\n",
            "Moyenne des précisions : 0.48\n",
            "\n",
            "Dossier 18_19_20_21_22_23 (train : 74.64% / test : 25.36%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.65\n",
            "Précision sur l'ensemble de test avec MLP : 0.27\n",
            "Précision sur l'ensemble de test avec GB : 0.53\n",
            "Moyenne des précisions : 0.48\n",
            "\n",
            "Dossier 12_13_14_15_16_17 (train : 75.05% / test : 24.95%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.63\n",
            "Précision sur l'ensemble de test avec MLP : 0.34\n",
            "Précision sur l'ensemble de test avec GB : 0.51\n",
            "Moyenne des précisions : 0.49\n",
            "\n",
            "Dossier 6_7_8_9_10_11 (train : 75.38% / test : 24.62%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.62\n",
            "Précision sur l'ensemble de test avec MLP : 0.28\n",
            "Précision sur l'ensemble de test avec GB : 0.52\n",
            "Moyenne des précisions : 0.47\n",
            "\n",
            "=======================================================================\n",
            "\n",
            "Moyenne des précisions avec RF : 0.64\n",
            "Moyenne des précisions avec MLP : 0.29\n",
            "Moyenne des précisions avec GB : 0.52\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}