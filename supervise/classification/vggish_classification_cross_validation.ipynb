{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification cross validation avec indices VGGISH"
      ],
      "metadata": {
        "id": "ncNRJdDj4dyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Ségrégation spatiale : Tests sur différents modèles"
      ],
      "metadata": {
        "id": "Tfq7ZEOy4xaF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ij8eV1rK4THK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89130c25-cde9-43eb-eda8-f386cdf72773"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def separate_integers_letters(string):\n",
        "    integers = ''.join(re.findall(r'\\d+', string))\n",
        "    letters = ''.join(re.findall(r'[a-zA-Z]+', string))\n",
        "    return integers, letters"
      ],
      "metadata": {
        "id": "7Z0A4_sc5jO4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dico_encodage = {'E_Bleu': 1, 'E_Rouge': 2, 'L_Bleu': 3, 'L_Rouge': 4}\n",
        "print(dico_encodage)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJGakXDxhhtZ",
        "outputId": "fced74ca-42de-48d9-e7b8-1a1628d3246d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'E_Bleu': 1, 'E_Rouge': 2, 'L_Bleu': 3, 'L_Rouge': 4}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def add_labels(df):\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    station_name_parts = row['station_name'].split('/')\n",
        "    position_dynamique = station_name_parts[2]\n",
        "    position_dynamique_parts = position_dynamique.split('_')\n",
        "    _, position = separate_integers_letters(position_dynamique_parts[1])\n",
        "    dynamique = position_dynamique_parts[2]\n",
        "\n",
        "    position_dynamique = position + '_' + dynamique\n",
        "\n",
        "    df.loc[index, 'label'] = dico_encodage[position_dynamique]\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "sJax4AKo5rzD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "def custom_cross_validation(model, X_train, y_train, X_test, y_test):\n",
        "    # Entraîner le modèle sur l'ensemble de données d'entraînement\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Prédire les étiquettes sur l'ensemble de test\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Calculer la précision du modèle\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "0o42kJik5-GK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Chemin vers le répertoire contenant les dossiers de données sur Google Drive\n",
        "data_directory = \"/content/gdrive/MyDrive/ListenToTheWild/vggish_cross_validation_spatial\"\n",
        "\n",
        "# Liste des dossiers dans le répertoire\n",
        "directories = sorted(os.listdir(data_directory))\n",
        "\n",
        "rf_mean_acc = 0\n",
        "mlp_mean_acc = 0\n",
        "gb_mean_acc = 0\n",
        "# Boucle sur chaque dossier\n",
        "for directory in directories:\n",
        "  # Chemin vers le dossier contenant les fichiers de train/test\n",
        "  directory_path = os.path.join(data_directory, directory)\n",
        "\n",
        "  # Charger les données d'entraînement\n",
        "  train_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_train.csv\"))\n",
        "  nb_rows_train = train_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  train_data_with_labels = add_labels(train_data)\n",
        "  # Supprimer les colonnes \"station_name\" et \"file_name\"\n",
        "  train_data_with_labels = train_data_with_labels.drop(['station_name', 'file_name'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_train = train_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_train = train_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Charger les données de test\n",
        "  test_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_test.csv\"))\n",
        "  nb_rows_test = test_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  test_data_with_labels = add_labels(test_data)\n",
        "  # Supprimer les colonnes \"station_name\" et \"file_name\"\n",
        "  test_data_with_labels = test_data_with_labels.drop(['station_name', 'file_name'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_test = test_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_test = test_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Créer les modèles\n",
        "  rf_model = RandomForestClassifier()\n",
        "  mlp_model = MLPClassifier()\n",
        "  gb_model = GradientBoostingClassifier()\n",
        "\n",
        "  # Effectuer les validations croisées personnalisées\n",
        "  rf_accuracy = custom_cross_validation(rf_model, X_train, y_train, X_test, y_test)\n",
        "  mlp_accuracy = custom_cross_validation(mlp_model, X_train, y_train, X_test, y_test)\n",
        "  gb_accuracy = custom_cross_validation(gb_model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "  # Calculer la moyenne des précisions\n",
        "  mean_accuracy = (rf_accuracy + mlp_accuracy + gb_accuracy)/3\n",
        "\n",
        "  # Ajouter les valeurs pour le calcul des moyennes\n",
        "  rf_mean_acc += rf_accuracy\n",
        "  mlp_mean_acc += mlp_accuracy\n",
        "  gb_mean_acc += gb_accuracy\n",
        "\n",
        "  # Calculer les pourcentages des ensembles\n",
        "  per_train_set = nb_rows_train / (nb_rows_train + nb_rows_test)\n",
        "  per_test_set = nb_rows_test / (nb_rows_train + nb_rows_test)\n",
        "\n",
        "  # Afficher les précisions sur l'ensemble de test\n",
        "  print(f\"Dossier {directory} (train : {round(per_train_set*100, 2)}% / test : {round(per_test_set*100, 2)}%) :\")\n",
        "  print(f\"Précision sur l'ensemble de test avec RF : {round(rf_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec MLP : {round(mlp_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec GB : {round(gb_accuracy, 2)}\")\n",
        "  print(f\"Moyenne des précisions : {round(mean_accuracy, 2)}\")\n",
        "  print()\n",
        "\n",
        "print(\"=======================================================================\")\n",
        "print()\n",
        "\n",
        "# Afficher les moyennes des précisions par modèle\n",
        "nb_dir = len(directories)\n",
        "print(f\"Moyenne des précisions avec RF : {round(rf_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec MLP : {round(mlp_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec GB : {round(gb_mean_acc/nb_dir, 2)}\")"
      ],
      "metadata": {
        "id": "x0aU51XS6Irq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "026d5f23-87a9-4472-f492-ddf1fb5b1217"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier Antras_Isard (train : 95.46% / test : 4.54%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.33\n",
            "Précision sur l'ensemble de test avec MLP : 0.36\n",
            "Précision sur l'ensemble de test avec GB : 0.4\n",
            "Moyenne des précisions : 0.36\n",
            "\n",
            "Dossier Appy_Etang_dAppy (train : 97.81% / test : 2.19%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.31\n",
            "Précision sur l'ensemble de test avec MLP : 0.42\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.36\n",
            "\n",
            "Dossier Arrien_Pic_Midi_Bordes (train : 95.68% / test : 4.32%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.41\n",
            "Précision sur l'ensemble de test avec MLP : 0.39\n",
            "Précision sur l'ensemble de test avec GB : 0.42\n",
            "Moyenne des précisions : 0.41\n",
            "\n",
            "Dossier Ascou_Pailheres (train : 98.02% / test : 1.98%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.24\n",
            "Précision sur l'ensemble de test avec MLP : 0.24\n",
            "Précision sur l'ensemble de test avec GB : 0.23\n",
            "Moyenne des précisions : 0.24\n",
            "\n",
            "Dossier Aston_Plateau_de_Beille (train : 98.14% / test : 1.86%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.32\n",
            "Précision sur l'ensemble de test avec MLP : 0.43\n",
            "Précision sur l'ensemble de test avec GB : 0.3\n",
            "Moyenne des précisions : 0.35\n",
            "\n",
            "Dossier Aulus_Turon_Rose (train : 97.8% / test : 2.2%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.52\n",
            "Précision sur l'ensemble de test avec MLP : 0.44\n",
            "Précision sur l'ensemble de test avec GB : 0.54\n",
            "Moyenne des précisions : 0.5\n",
            "\n",
            "Dossier Bestiac_Trimouns (train : 97.24% / test : 2.76%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.37\n",
            "Précision sur l'ensemble de test avec MLP : 0.33\n",
            "Précision sur l'ensemble de test avec GB : 0.3\n",
            "Moyenne des précisions : 0.33\n",
            "\n",
            "Dossier Bethmale_Ayet (train : 99.06% / test : 0.94%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.26\n",
            "Précision sur l'ensemble de test avec MLP : 0.49\n",
            "Précision sur l'ensemble de test avec GB : 0.22\n",
            "Moyenne des précisions : 0.32\n",
            "\n",
            "Dossier Bethmale_Eychelle (train : 98.1% / test : 1.9%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.37\n",
            "Précision sur l'ensemble de test avec MLP : 0.37\n",
            "Précision sur l'ensemble de test avec GB : 0.37\n",
            "Moyenne des précisions : 0.37\n",
            "\n",
            "Dossier Bonac_Arech (train : 97.48% / test : 2.52%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.39\n",
            "Précision sur l'ensemble de test avec MLP : 0.32\n",
            "Précision sur l'ensemble de test avec GB : 0.41\n",
            "Moyenne des précisions : 0.37\n",
            "\n",
            "Dossier Bonac_Orle (train : 95.61% / test : 4.39%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.2\n",
            "Précision sur l'ensemble de test avec MLP : 0.26\n",
            "Précision sur l'ensemble de test avec GB : 0.23\n",
            "Moyenne des précisions : 0.23\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier Couflens_Pouill (train : 99.08% / test : 0.92%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.41\n",
            "Précision sur l'ensemble de test avec MLP : 0.46\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.4\n",
            "\n",
            "Dossier Couflens_Saubé (train : 99.34% / test : 0.66%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.35\n",
            "Précision sur l'ensemble de test avec MLP : 0.75\n",
            "Précision sur l'ensemble de test avec GB : 0.32\n",
            "Moyenne des précisions : 0.47\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier Formiguères_Serra_dels_Alarbs (train : 95.7% / test : 4.3%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.38\n",
            "Précision sur l'ensemble de test avec MLP : 0.29\n",
            "Précision sur l'ensemble de test avec GB : 0.4\n",
            "Moyenne des précisions : 0.35\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier Gestiès_Col_du_Sasc (train : 98.58% / test : 1.42%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.22\n",
            "Précision sur l'ensemble de test avec MLP : 0.18\n",
            "Précision sur l'ensemble de test avec GB : 0.23\n",
            "Moyenne des précisions : 0.21\n",
            "\n",
            "Dossier Gestiès_Le_Clot (train : 97.82% / test : 2.18%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.41\n",
            "Précision sur l'ensemble de test avec MLP : 0.43\n",
            "Précision sur l'ensemble de test avec GB : 0.37\n",
            "Moyenne des précisions : 0.4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier Goulier_Val_de_Sos (train : 98.19% / test : 1.81%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.29\n",
            "Précision sur l'ensemble de test avec MLP : 0.32\n",
            "Précision sur l'ensemble de test avec GB : 0.3\n",
            "Moyenne des précisions : 0.3\n",
            "\n",
            "Dossier Lercoul_Col_de_Grail (train : 98.14% / test : 1.86%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.42\n",
            "Précision sur l'ensemble de test avec MLP : 0.35\n",
            "Précision sur l'ensemble de test avec GB : 0.45\n",
            "Moyenne des précisions : 0.41\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier Les_Angles_Puig_del_Pam (train : 95.33% / test : 4.67%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.29\n",
            "Précision sur l'ensemble de test avec MLP : 0.25\n",
            "Précision sur l'ensemble de test avec GB : 0.3\n",
            "Moyenne des précisions : 0.28\n",
            "\n",
            "Dossier Les_Angles_Roc_dAude (train : 95.42% / test : 4.58%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.34\n",
            "Précision sur l'ensemble de test avec MLP : 0.33\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.34\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier Merens_Comte (train : 95.99% / test : 4.01%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.17\n",
            "Précision sur l'ensemble de test avec MLP : 0.27\n",
            "Précision sur l'ensemble de test avec GB : 0.12\n",
            "Moyenne des précisions : 0.19\n",
            "\n",
            "Dossier Miglos_Pla_de_Montcamp (train : 98.14% / test : 1.86%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.22\n",
            "Précision sur l'ensemble de test avec MLP : 0.26\n",
            "Précision sur l'ensemble de test avec GB : 0.22\n",
            "Moyenne des précisions : 0.23\n",
            "\n",
            "Dossier Mijanes_Estagnet (train : 96.3% / test : 3.7%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.26\n",
            "Précision sur l'ensemble de test avec MLP : 0.24\n",
            "Précision sur l'ensemble de test avec GB : 0.22\n",
            "Moyenne des précisions : 0.24\n",
            "\n",
            "Dossier Mijanes_Trabesses (train : 97.3% / test : 2.7%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.29\n",
            "Précision sur l'ensemble de test avec MLP : 0.23\n",
            "Précision sur l'ensemble de test avec GB : 0.29\n",
            "Moyenne des précisions : 0.27\n",
            "\n",
            "Dossier Montferrier_Mont_dOlmes (train : 97.46% / test : 2.54%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.4\n",
            "Précision sur l'ensemble de test avec MLP : 0.29\n",
            "Précision sur l'ensemble de test avec GB : 0.38\n",
            "Moyenne des précisions : 0.36\n",
            "\n",
            "Dossier Montsegur_Frau (train : 98.88% / test : 1.12%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.43\n",
            "Précision sur l'ensemble de test avec MLP : 0.42\n",
            "Précision sur l'ensemble de test avec GB : 0.43\n",
            "Moyenne des précisions : 0.43\n",
            "\n",
            "Dossier Montségur_Soularac (train : 94.78% / test : 5.22%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.3\n",
            "Précision sur l'ensemble de test avec MLP : 0.34\n",
            "Précision sur l'ensemble de test avec GB : 0.3\n",
            "Moyenne des précisions : 0.31\n",
            "\n",
            "Dossier Orgeix_Coume (train : 97.55% / test : 2.45%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.28\n",
            "Précision sur l'ensemble de test avec MLP : 0.27\n",
            "Précision sur l'ensemble de test avec GB : 0.26\n",
            "Moyenne des précisions : 0.27\n",
            "\n",
            "Dossier Orlu_RNCFS (train : 96.31% / test : 3.69%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.41\n",
            "Précision sur l'ensemble de test avec MLP : 0.38\n",
            "Précision sur l'ensemble de test avec GB : 0.41\n",
            "Moyenne des précisions : 0.4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier Saint-Lary_Herbe_Soulette (train : 98.02% / test : 1.98%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.37\n",
            "Précision sur l'ensemble de test avec MLP : 0.37\n",
            "Précision sur l'ensemble de test avec GB : 0.34\n",
            "Moyenne des précisions : 0.36\n",
            "\n",
            "Dossier Seix_Col_de_Pause (train : 98.23% / test : 1.77%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.5\n",
            "Précision sur l'ensemble de test avec MLP : 0.25\n",
            "Précision sur l'ensemble de test avec GB : 0.53\n",
            "Moyenne des précisions : 0.43\n",
            "\n",
            "Dossier Seix_Pic_de_Montbuou (train : 95.73% / test : 4.27%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.47\n",
            "Précision sur l'ensemble de test avec MLP : 0.51\n",
            "Précision sur l'ensemble de test avec GB : 0.48\n",
            "Moyenne des précisions : 0.49\n",
            "\n",
            "Dossier Sentein_Eylie (train : 95.89% / test : 4.11%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.31\n",
            "Précision sur l'ensemble de test avec MLP : 0.35\n",
            "Précision sur l'ensemble de test avec GB : 0.32\n",
            "Moyenne des précisions : 0.33\n",
            "\n",
            "Dossier Ustou_Col_dEscots (train : 95.93% / test : 4.07%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.21\n",
            "Précision sur l'ensemble de test avec MLP : 0.27\n",
            "Précision sur l'ensemble de test avec GB : 0.17\n",
            "Moyenne des précisions : 0.21\n",
            "\n",
            "Dossier Ustou_Guzet-Neige (train : 98.76% / test : 1.24%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.21\n",
            "Précision sur l'ensemble de test avec MLP : 0.01\n",
            "Précision sur l'ensemble de test avec GB : 0.16\n",
            "Moyenne des précisions : 0.13\n",
            "\n",
            "Dossier Valcebollère_Pla_des_Salines (train : 96.73% / test : 3.27%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.19\n",
            "Précision sur l'ensemble de test avec MLP : 0.34\n",
            "Précision sur l'ensemble de test avec GB : 0.19\n",
            "Moyenne des précisions : 0.24\n",
            "\n",
            "=======================================================================\n",
            "\n",
            "Moyenne des précisions avec RF : 0.33\n",
            "Moyenne des précisions avec MLP : 0.34\n",
            "Moyenne des précisions avec GB : 0.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Ségrégation temporelle : Tests sur différents modèles"
      ],
      "metadata": {
        "id": "kO475m8d8W62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "\n",
        "# Chemin vers le répertoire contenant les dossiers de données sur Google Drive\n",
        "data_directory = \"/content/gdrive/MyDrive/ListenToTheWild/vggish_cross_validation_temporal\"\n",
        "\n",
        "# Liste des dossiers dans le répertoire\n",
        "directories = os.listdir(data_directory)\n",
        "\n",
        "rf_mean_acc = 0\n",
        "mlp_mean_acc = 0\n",
        "gb_mean_acc = 0\n",
        "# Boucle sur chaque dossier\n",
        "for directory in directories:\n",
        "  # Chemin vers le dossier contenant les fichiers de train/test\n",
        "  directory_path = os.path.join(data_directory, directory)\n",
        "\n",
        "  # Charger les données d'entraînement\n",
        "  train_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_train.csv\"))\n",
        "  nb_rows_train = train_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  train_data_with_labels = add_labels(train_data)\n",
        "  # Supprimer les colonnes \"station_name\" et \"file_name\"\n",
        "  train_data_with_labels = train_data_with_labels.drop(['station_name', 'file_name'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_train = train_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_train = train_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Charger les données de test\n",
        "  test_data = pd.read_csv(os.path.join(directory_path, f\"{directory}_test.csv\"))\n",
        "  nb_rows_test = test_data.shape[0]\n",
        "  # Ajouter les labels\n",
        "  test_data_with_labels = add_labels(test_data)\n",
        "  # Supprimer les colonnes \"station_name\" et \"file_name\"\n",
        "  test_data_with_labels = test_data_with_labels.drop(['station_name', 'file_name'], axis=1)\n",
        "  # Créer X et y\n",
        "  X_test = test_data_with_labels.drop(columns=['label'])  # attributs\n",
        "  y_test = test_data_with_labels['label']  # étiquettes\n",
        "\n",
        "  # Créer les modèles\n",
        "  rf_model = RandomForestClassifier()\n",
        "  mlp_model = MLPClassifier()\n",
        "  gb_model = GradientBoostingClassifier()\n",
        "\n",
        "  # Effectuer les validations croisées personnalisées\n",
        "  rf_accuracy = custom_cross_validation(rf_model, X_train, y_train, X_test, y_test)\n",
        "  mlp_accuracy = custom_cross_validation(mlp_model, X_train, y_train, X_test, y_test)\n",
        "  gb_accuracy = custom_cross_validation(gb_model, X_train, y_train, X_test, y_test)\n",
        "\n",
        "  # Calculer la moyenne des précisions\n",
        "  mean_accuracy = (rf_accuracy + mlp_accuracy + gb_accuracy)/3\n",
        "\n",
        "  # Ajouter les valeurs pour le calcul des moyennes\n",
        "  rf_mean_acc += rf_accuracy\n",
        "  mlp_mean_acc += mlp_accuracy\n",
        "  gb_mean_acc += gb_accuracy\n",
        "\n",
        "  # Calculer les pourcentages des ensembles\n",
        "  per_train_set = nb_rows_train / (nb_rows_train + nb_rows_test)\n",
        "  per_test_set = nb_rows_test / (nb_rows_train + nb_rows_test)\n",
        "\n",
        "  # Afficher les précisions sur l'ensemble de test\n",
        "  print(f\"Dossier {directory} (train : {round(per_train_set*100, 2)}% / test : {round(per_test_set*100, 2)}%) :\")\n",
        "  print(f\"Précision sur l'ensemble de test avec RF : {round(rf_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec MLP : {round(mlp_accuracy, 2)}\")\n",
        "  print(f\"Précision sur l'ensemble de test avec GB : {round(gb_accuracy, 2)}\")\n",
        "  print(f\"Moyenne des précisions : {round(mean_accuracy, 2)}\")\n",
        "  print()\n",
        "\n",
        "print(\"=======================================================================\")\n",
        "print()\n",
        "\n",
        "# Afficher les moyennes des précisions par modèle\n",
        "nb_dir = len(directories)\n",
        "print(f\"Moyenne des précisions avec RF : {round(rf_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec MLP : {round(mlp_mean_acc/nb_dir, 2)}\")\n",
        "print(f\"Moyenne des précisions avec GB : {round(gb_mean_acc/nb_dir, 2)}\")"
      ],
      "metadata": {
        "id": "wTfH31U38ies",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ef4e628-1ab0-4379-edf7-261fac19bd0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dossier 18_19_20_21_22_23 (train : 74.64% / test : 25.36%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.61\n",
            "Précision sur l'ensemble de test avec MLP : 0.27\n",
            "Précision sur l'ensemble de test avec GB : 0.53\n",
            "Moyenne des précisions : 0.47\n",
            "\n",
            "Dossier 12_13_14_15_16_17 (train : 75.05% / test : 24.95%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.58\n",
            "Précision sur l'ensemble de test avec MLP : 0.46\n",
            "Précision sur l'ensemble de test avec GB : 0.52\n",
            "Moyenne des précisions : 0.52\n",
            "\n",
            "Dossier 0_1_2_3_4_5 (train : 74.93% / test : 25.07%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.62\n",
            "Précision sur l'ensemble de test avec MLP : 0.52\n",
            "Précision sur l'ensemble de test avec GB : 0.53\n",
            "Moyenne des précisions : 0.56\n",
            "\n",
            "Dossier 6_7_8_9_10_11 (train : 75.38% / test : 24.62%) :\n",
            "Précision sur l'ensemble de test avec RF : 0.57\n",
            "Précision sur l'ensemble de test avec MLP : 0.41\n",
            "Précision sur l'ensemble de test avec GB : 0.51\n",
            "Moyenne des précisions : 0.5\n",
            "\n",
            "=======================================================================\n",
            "\n",
            "Moyenne des précisions avec RF : 0.6\n",
            "Moyenne des précisions avec MLP : 0.42\n",
            "Moyenne des précisions avec GB : 0.52\n"
          ]
        }
      ]
    }
  ]
}